from airflow import DAG
from airflow.operators.python import PythonOperator, ShortCircuitOperator
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from prophet import Prophet
import logging
from google.cloud import bigquery
import os
import json

# [í™˜ê²½ ì„¤ì •]
PROJECT_ID = os.getenv("VERTEX_AI_PROJECT_ID", "project-5b75bb04-485d-454e-af7")
DATASET_ID = "tilda"
PRICE_TABLE = "wheat_price"
TARGET_TABLE = "prophet_wheat"
COMMODITY = "wheat"
START_DATE = datetime(2024, 1, 1)

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': START_DATE,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def get_bq_client():
    return bigquery.Client(project=PROJECT_ID)

def check_already_exists(**context):
    """ì´ë¯¸ í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì ìž¬ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸"""
    target_date = context['ds']
    client = get_bq_client()
    query = f"SELECT count(*) as cnt FROM `{PROJECT_ID}.{DATASET_ID}.{TARGET_TABLE}` WHERE ds = '{target_date}'"
    try:
        df = client.query(query).to_dataframe()
        if df['cnt'].iloc[0] > 0:
            logging.info(f"[PRICE-MODEL][{COMMODITY}] âœ… {target_date} ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤. ìž‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        return True
    except Exception as e:
        logging.warning(f"[PRICE-MODEL][{COMMODITY}] âš ï¸ ì²´í¬ ì‹¤íŒ¨ (ì§„í–‰): {e}")
        return True

def generate_features(**context):
    """
    Airflow ì‹¤í–‰ ë‚ ì§œ(ds)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Prophet ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (prophet_wheat.py ë¡œì§ê³¼ 100% ì¼ì¹˜í™”)
    """
    target_date_str = context['ds']
    target_date = pd.to_datetime(target_date_str)
    
    logging.info(f"[PRICE-MODEL][{COMMODITY}] ðŸš€ Task ì‹œìž‘: generate_features (Target: {target_date_str})")
    
    client = get_bq_client()
    start_date = target_date - timedelta(days=365 * 4 + 30)
    start_date_str = start_date.strftime('%Y-%m-%d')
    
    # 1. Wheat ë°ì´í„° ë¡œë“œ
    q_wheat = f"SELECT time, close, open, high, low, volume as Volume, ema as EMA FROM `{PROJECT_ID}.{DATASET_ID}.{PRICE_TABLE}` WHERE DATE(time) >= '{start_date_str}' AND DATE(time) <= '{target_date_str}' ORDER BY time"
    df = client.query(q_wheat).to_dataframe()
    
    if df.empty or df.iloc[-1]['time'].strftime('%Y-%m-%d') != target_date_str:
        logging.warning(f"[PRICE-MODEL][{COMMODITY}] âš ï¸ {target_date_str} ë°ì´í„° ë¶€ìž¬ë¡œ ì¤‘ë‹¨.")
        return None

    df['ds'] = pd.to_datetime(df['time'])
    df['y'] = pd.to_numeric(df['close'])
    
    # 2. ë³´ì¡° ë°ì´í„°(Corn, Soybean) ë¡œë“œ (Granger ê¸°ë°˜)
    for dep in ['corn', 'soybean']:
        q_dep = f"SELECT time, close as {dep}_close FROM `{PROJECT_ID}.{DATASET_ID}.{dep}_price` WHERE DATE(time) >= '{start_date_str}' AND DATE(time) <= '{target_date_str}' ORDER BY time"
        try:
            df_dep = client.query(q_dep).to_dataframe()
            df_dep['time'] = pd.to_datetime(df_dep['time'])
            df = pd.merge(df, df_dep, on='time', how='left')
        except Exception: df[f'{dep}_close'] = np.nan

    # 3. Granger Lag í”¼ì²˜ ìƒì„±
    # Wheat íŠ¹í™”: EMA_lag1, Volume_lag1, corn_close_lag2, soybean_close_lag1
    df['EMA_lag1'] = df['EMA'].shift(1).astype(float)
    df['Volume_lag1'] = df['Volume'].shift(1).astype(float)
    df['corn_close_lag2'] = df['corn_close'].shift(2).astype(float)
    df['soybean_close_lag1'] = df['soybean_close'].shift(1).astype(float)
    
    # í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (target_date ì „ë‚ ê¹Œì§€)
    train_df = df[df['ds'] < target_date].dropna(subset=['EMA_lag1', 'Volume_lag1']).copy()
    
    # ì¡°ê±´ë¶€ Regressors ì²´í¬
    use_corn, use_soybean = False, False
    regressors = ['EMA_lag1', 'Volume_lag1']
    
    if 'corn_close_lag2' in train_df.columns and train_df['corn_close_lag2'].notna().mean() > 0.5:
        use_corn = True
        regressors.append('corn_close_lag2')
    if 'soybean_close_lag1' in train_df.columns and train_df['soybean_close_lag1'].notna().mean() > 0.5:
        use_soybean = True
        regressors.append('soybean_close_lag1')
        
    train_df = train_df.dropna(subset=regressors)
    logging.info(f"[PRICE-MODEL][{COMMODITY}] ðŸ§  í•™ìŠµ ë°ì´í„°: {len(train_df)}í–‰, Regressors: {regressors}")
    
    # 4. Prophet ëª¨ë¸ í•™ìŠµ
    model = Prophet(seasonality_mode='multiplicative', yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)
    for reg in regressors: model.add_regressor(reg, mode='multiplicative')
    model.fit(train_df[['ds', 'y'] + regressors])
    
    # 5. ì˜ˆì¸¡
    future_row = df[df['ds'] == target_date].copy()
    if future_row[regressors].isna().any().any():
        future_row[regressors] = future_row[regressors].fillna(method='ffill')
        
    forecast = model.predict(future_row)
    
    # 6. ê²°ê³¼ ì •ë¦¬
    res = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper', 'trend']].iloc[0].to_dict()
    for col in ['weekly', 'yearly', 'extra_regressors_multiplicative']:
        res[col] = forecast[col].iloc[0] if col in forecast.columns else None
    for reg in regressors:
        res[f"{reg}_effect"] = forecast[reg].iloc[0] if reg in forecast.columns else None
            
    prev_idx = df[df['ds'] == target_date].index[0] - 1
    res['y'] = float(df.iloc[prev_idx]['y']) if prev_idx >= 0 else None
    res['y_next'] = float(future_row['y'].iloc[0])
    
    if res['y'] is not None and res['y_next'] is not None:
        res['y_change'] = res['y_next'] - res['y']
        res['direction'] = 1 if res['y_change'] > 0 else 0
        res['predicted_direction'] = 1 if res['yhat'] > res['y'] else 0
        res['actual_direction'] = res['direction']
    else:
        res['y_change'], res['direction'], res['predicted_direction'], res['actual_direction'] = None, None, None, None

    res['Volume'] = int(future_row['Volume'].iloc[0])
    res['EMA'] = float(future_row['EMA'].iloc[0])
    res['corn_close'] = float(future_row['corn_close'].iloc[0]) if not pd.isna(future_row['corn_close'].iloc[0]) else None
    res['soybean_close'] = float(future_row['soybean_close'].iloc[0]) if not pd.isna(future_row['soybean_close'].iloc[0]) else None
    res['EMA_lag1'] = float(future_row['EMA_lag1'].iloc[0])
    res['Volume_lag1'] = float(future_row['Volume_lag1'].iloc[0])
    res['corn_close_lag2'] = float(future_row['corn_close_lag2'].iloc[0]) if use_corn else None
    res['soybean_close_lag1'] = float(future_row['soybean_close_lag1'].iloc[0]) if use_soybean else None
    
    res['used_corn'] = bool(use_corn)
    res['used_soybean'] = bool(use_soybean)
    res['volatility'] = float(res['yhat_upper'] - res['yhat_lower'])
    res['ds'] = res['ds'].strftime('%Y-%m-%d')
    
    return res

def insert_to_bq(**context):
    feature_data = context['ti'].xcom_pull(task_ids='generate_features')
    if not feature_data: return
    client = get_bq_client()
    table_id = f"{PROJECT_ID}.{DATASET_ID}.{TARGET_TABLE}"
    row = {k: (None if pd.isna(v) else v) for k, v in feature_data.items()}
    logging.info(f"[PRICE-MODEL][{COMMODITY}] ðŸ” ì ìž¬ ì˜ˆì • ë°ì´í„°:\n{json.dumps(row, indent=2, ensure_ascii=False)}")
    errors = client.insert_rows_json(table_id, [row])
    if errors: raise RuntimeError(f"BQ ì ìž¬ ì‹¤íŒ¨: {errors}")
    logging.info(f"[PRICE-MODEL][{COMMODITY}] âœ… ì ìž¬ ì™„ë£Œ ì„±ê³µ!")

with DAG(
    'generate_prophet_features_wheat_v1',
    default_args=default_args,
    description='Wheat Prophet í”¼ì²˜ ìƒì„± (ì¡´ìž¬ ì‹œ Skip)',
    schedule_interval='50 16 * * *',
    catchup=True,
    max_active_runs=1,
    tags=['wheat', 'prophet', 'feature_engineering']
) as dag:
    t0 = ShortCircuitOperator(task_id='check_exists', python_callable=check_already_exists, provide_context=True)
    t1 = PythonOperator(task_id='generate_features', python_callable=generate_features, provide_context=True)
    t2 = PythonOperator(task_id='insert_to_bq', python_callable=insert_to_bq, provide_context=True)
    t0 >> t1 >> t2