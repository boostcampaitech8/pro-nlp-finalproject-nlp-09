from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from airflow.models import Variable
from datetime import datetime, timedelta
import sys
import os
import json

# [í™˜ê²½ ì„¤ì •] ì„œë²„ ë°°í¬ ê²½ë¡œ ë°˜ì˜
PROJECT_ROOT = "/data/ephemeral/home/jb/pro-nlp-finalproject-nlp-09" 
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)
    # app ë””ë ‰í† ë¦¬ ì¶”ê°€
    app_dir = os.path.join(PROJECT_ROOT, "app")
    if app_dir not in sys.path:
        sys.path.append(app_dir)

try:
    from app.routes.orchestrator import run_market_analysis
    from app.utils.data_loader import load_timeseries_prediction, load_news_prediction, upload_report_to_gcs
    from app.config.settings import BIGQUERY_DATASET_ID
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    run_market_analysis = None
    load_timeseries_prediction = None
    load_news_prediction = None
    upload_report_to_gcs = None
    BIGQUERY_DATASET_ID = "tilda"

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2025, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'market_prediction_loader_v1',
    default_args=default_args,
    description='ì‹œìž¥ ì˜ˆì¸¡ ë¶„ì„ ë° ì‹œê³„ì—´ ë°ì´í„° ì ìž¬ íŒŒì´í”„ë¼ì¸ (Tilda Dataset)',
    schedule_interval='@daily',
    catchup=False,
    tags=['market', 'prediction', 'bigquery', 'tilda']
) as dag:

    def analyze_market_task(**context):
        """ì‹œìž¥ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ XComì— ì €ìž¥"""
        if not run_market_analysis:
            raise ImportError("run_market_analysis í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. PROJECT_ROOTë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
        execution_date = context['ds'] 
        # [í…ŒìŠ¤íŠ¸ ê³µì§€] í˜„ìž¬ ë°ì´í„° ë¶€ìž¬ ë°©ì§€ë¥¼ ìœ„í•´ 2025-11-10ë¡œ ê³ ì •í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.
        target_date = "2025-11-10" 
        
        print(f"ðŸš€ [Task 1] ì‹œìž¥ ë¶„ì„ ì‹œìž‘ (Target: {target_date}, RunDate: {execution_date})")
        result = run_market_analysis(target_date=target_date)
        return result

    def load_timeseries_task(**context):
        """XComì—ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ ì‹œê³„ì—´ í…Œì´ë¸”ì— ì ìž¬"""
        if not load_timeseries_prediction:
            raise ImportError("load_timeseries_prediction í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        analysis_result = context['ti'].xcom_pull(task_ids='run_analysis')
        if not analysis_result:
            raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (XCom Pull Failed).")
            
        timeseries_data = analysis_result.get('timeseries_data')
        if not timeseries_data:
            print("âš ï¸ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì ìž¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        print(f"ðŸ’¾ [Task 2] ì‹œê³„ì—´ ë°ì´í„° ì ìž¬ ì‹œìž‘ (Dataset: {BIGQUERY_DATASET_ID})")
        load_timeseries_prediction(timeseries_data, dataset_id=BIGQUERY_DATASET_ID)

    def load_news_task(**context):
        """XComì—ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ ë‰´ìŠ¤ í…Œì´ë¸”ì— ì ìž¬"""
        if not load_news_prediction:
            raise ImportError("load_news_prediction í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        analysis_result = context['ti'].xcom_pull(task_ids='run_analysis')
        if not analysis_result:
            raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        news_data = analysis_result.get('news_data')
        if not news_data:
            print("âš ï¸ ë‰´ìŠ¤ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì ìž¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        print(f"ðŸ’¾ [Task 3] ë‰´ìŠ¤ ë°ì´í„° ì ìž¬ ì‹œìž‘ (Dataset: {BIGQUERY_DATASET_ID})")
        load_news_prediction(news_data, dataset_id=BIGQUERY_DATASET_ID)

    def upload_report_task(**context):
        """XComì—ì„œ ë¦¬í¬íŠ¸ë¥¼ ë°›ì•„ GCSì— ì—…ë¡œë“œ"""
        if not upload_report_to_gcs:
            raise ImportError("upload_report_to_gcs í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        analysis_result = context['ti'].xcom_pull(task_ids='run_analysis')
        if not analysis_result:
            raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        final_report = analysis_result.get('final_report')
        target_date = analysis_result.get('target_date')
        
        if not final_report:
            print("âš ï¸ ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        BUCKET_NAME = "agri-market-reports" 
        print(f"â˜ï¸ [Task 4] ë¦¬í¬íŠ¸ GCS ì—…ë¡œë“œ ì‹œìž‘ (Bucket: {BUCKET_NAME})")
        upload_report_to_gcs(final_report, target_date, bucket_name=BUCKET_NAME)

    # Task ì •ì˜
    t1_analyze = PythonOperator(
        task_id='run_analysis',
        python_callable=analyze_market_task,
        provide_context=True
    )

    t2_load_timeseries = PythonOperator(
        task_id='load_timeseries',
        python_callable=load_timeseries_task,
        provide_context=True
    )

    t3_load_news = PythonOperator(
        task_id='load_news',
        python_callable=load_news_task,
        provide_context=True
    )

    t4_upload_report = PythonOperator(
        task_id='upload_report',
        python_callable=upload_report_task,
        provide_context=True
    )

    # ì‹¤í–‰ ìˆœì„œ: ë¶„ì„ -> [ì‹œê³„ì—´ ì ìž¬, ë‰´ìŠ¤ ì ìž¬, ë¦¬í¬íŠ¸ ì—…ë¡œë“œ] ë³‘ë ¬ ì‹¤í–‰
    t1_analyze >> [t2_load_timeseries, t3_load_news, t4_upload_report]