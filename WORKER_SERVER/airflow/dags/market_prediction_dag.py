from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from datetime import datetime, timedelta
import sys
import os
import json

# [í™˜ê²½ ì„¤ì •] ì„œë²„ ë°°í¬ ê²½ë¡œ ë°˜ì˜
PROJECT_ROOT = "/data/ephemeral/home/jb/pro-nlp-finalproject-nlp-09" 
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)
    # app ë””ë ‰í† ë¦¬ ì¶”ê°€
    app_dir = os.path.join(PROJECT_ROOT, "app")
    if app_dir not in sys.path:
        sys.path.append(app_dir)

try:
    from app.routes.orchestrator import run_market_analysis
    from app.utils.data_loader import load_timeseries_prediction, load_news_prediction, upload_report_to_gcs
    from app.config.settings import BIGQUERY_DATASET_ID
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    run_market_analysis = None
    load_timeseries_prediction = None
    load_news_prediction = None
    upload_report_to_gcs = None
    BIGQUERY_DATASET_ID = "tilda"

# ë¶„ì„ ëŒ€ìƒ í’ˆëª© ë¦¬ìŠ¤íŠ¸
COMMODITIES = ["corn", "soybean", "wheat"]

def create_dag(commodity_name):
    """
    í’ˆëª©ë³„ DAGë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    default_args = {
        'owner': 'airflow',
        'depends_on_past': False,
        'start_date': datetime(2025, 1, 1),
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
    }

    dag_id = f'market_prediction_{commodity_name}_v1'
    
    dag = DAG(
        dag_id,
        default_args=default_args,
        description=f'{commodity_name} ì‹œì¥ ì˜ˆì¸¡ ë¶„ì„ ë° ë°ì´í„° ì ì¬ íŒŒì´í”„ë¼ì¸',
        schedule_interval='0 0 * * 1-5',  # í‰ì¼ ìì • ì‹¤í–‰
        max_active_runs=1,
        catchup=True,
        tags=['market', 'prediction', 'bigquery', 'tilda', commodity_name]
    )

    with dag:
        def analyze_market_task(**context):
            """ì‹œì¥ ë¶„ì„ ìˆ˜í–‰"""
            if not run_market_analysis:
                raise ImportError("run_market_analysis í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
            execution_date = context['ds'] 
            # [í…ŒìŠ¤íŠ¸ ê³µì§€] í˜„ì¬ ë°ì´í„° ë¶€ì¬ ë°©ì§€ë¥¼ ìœ„í•´ 2025-11-10ë¡œ ê³ ì •í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.
            target_date = "2025-11-10" 
            
            print(f"ğŸš€ [{commodity_name}] ì‹œì¥ ë¶„ì„ ì‹œì‘ (Target: {target_date}, RunDate: {execution_date})")
            # commodity ì¸ì ì „ë‹¬
            result = run_market_analysis(target_date=target_date, commodity=commodity_name)
            return result

        def load_timeseries_task(**context):
            """ì‹œê³„ì—´ ë°ì´í„° ì ì¬"""
            if not load_timeseries_prediction:
                raise ImportError("load_timeseries_prediction í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            analysis_result = context['ti'].xcom_pull(task_ids='run_analysis')
            if not analysis_result: raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
            timeseries_data = analysis_result.get('timeseries_data')
            if not timeseries_data:
                print(f"âš ï¸ [{commodity_name}] ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì ì¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return

            print(f"ğŸ’¾ [{commodity_name}] ì‹œê³„ì—´ ë°ì´í„° ì ì¬ ì‹œì‘ (Dataset: {BIGQUERY_DATASET_ID})")
            # commodity ì¸ì ì „ë‹¬
            load_timeseries_prediction(timeseries_data, commodity=commodity_name, dataset_id=BIGQUERY_DATASET_ID)

        def load_news_task(**context):
            """ë‰´ìŠ¤ ë°ì´í„° ì ì¬"""
            if not load_news_prediction:
                raise ImportError("load_news_prediction í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            analysis_result = context['ti'].xcom_pull(task_ids='run_analysis')
            if not analysis_result: raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
            news_data = analysis_result.get('news_data')
            if not news_data:
                print(f"âš ï¸ [{commodity_name}] ë‰´ìŠ¤ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì ì¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return

            print(f"ğŸ’¾ [{commodity_name}] ë‰´ìŠ¤ ë°ì´í„° ì ì¬ ì‹œì‘")
            # commodity ì¸ì ì „ë‹¬
            load_news_prediction(news_data, commodity=commodity_name, dataset_id=BIGQUERY_DATASET_ID)

        def upload_report_task(**context):
            """ë¦¬í¬íŠ¸ GCS ì—…ë¡œë“œ"""
            if not upload_report_to_gcs:
                raise ImportError("upload_report_to_gcs í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            analysis_result = context['ti'].xcom_pull(task_ids='run_analysis')
            if not analysis_result: raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
            final_report = analysis_result.get('final_report')
            target_date = analysis_result.get('target_date')
            
            if not final_report:
                print(f"âš ï¸ [{commodity_name}] ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return

            BUCKET_NAME = "team-blue-raw-data" 
            print(f"â˜ï¸ [{commodity_name}] ë¦¬í¬íŠ¸ GCS ì—…ë¡œë“œ ì‹œì‘")
            # commodity ì¸ì ì „ë‹¬
            upload_report_to_gcs(final_report, target_date, commodity=commodity_name, bucket_name=BUCKET_NAME)

        # Task ì •ì˜
        t1_analyze = PythonOperator(
            task_id='run_analysis',
            python_callable=analyze_market_task,
            provide_context=True
        )

        t2_load_timeseries = PythonOperator(
            task_id='load_timeseries',
            python_callable=load_timeseries_task,
            provide_context=True
        )

        t3_load_news = PythonOperator(
            task_id='load_news',
            python_callable=load_news_task,
            provide_context=True
        )

        t4_upload_report = PythonOperator(
            task_id='upload_report',
            python_callable=upload_report_task,
            provide_context=True
        )

        # ì‹¤í–‰ ìˆœì„œ
        t1_analyze >> [t2_load_timeseries, t3_load_news, t4_upload_report]

    return dag

# ë™ì  DAG ìƒì„± (Global Scopeì— DAG ê°ì²´ê°€ ë…¸ì¶œë˜ì–´ì•¼ Airflowê°€ ì¸ì‹í•¨)
for commodity in COMMODITIES:
    dag_id = f'market_prediction_{commodity}_v1'
    globals()[dag_id] = create_dag(commodity)
