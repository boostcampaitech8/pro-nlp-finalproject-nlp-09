import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import yaml
import pickle
from tqdm import tqdm
import warnings
import random
import os
from typing import Dict, Any
warnings.filterwarnings('ignore')

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)


def load_config(config_path=None):
    """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if config_path is None:
        # ê¸°ë³¸ ê²½ë¡œ: í˜„ì¬ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì˜ config.yaml
        base_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(base_dir, 'config.yaml')
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def load_prophet_features(filepath):
    """Prophet features CSV ë¡œë“œ"""
    print("ğŸ“‚ Prophet features ë¡œë”© ì¤‘...")
    df = pd.read_csv(filepath)
    df['ds'] = pd.to_datetime(df['ds'])
    print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰\n")
    return df


def train_xgboost_walkforward(df, config):
    """
    Walk-Forward ë°©ì‹ìœ¼ë¡œ XGBoost í•™ìŠµ ë° ì˜ˆì¸¡
    ë§¤ ì‹œì ë§ˆë‹¤ ëª¨ë¸ì„ ì¬í•™ìŠµ
    """
    xgb_config = config['xgboost']
    validation_config = config['validation']
    min_train_samples = validation_config['min_train_samples']
    window_size = validation_config.get('window_size', None)  
    
    print("\nğŸš€ Walk-Forward ë°©ì‹ìœ¼ë¡œ XGBoost í•™ìŠµ ì‹œì‘...")

    feature_columns = [
        col
        for col in df.columns
        if col not in ["ds", "y", "direction", "y_change", "yhat_lower", "yhat_upper"]
    ]

    print(f"ì‚¬ìš©í•  Features ({len(feature_columns)}ê°œ):")
    for col in feature_columns:
        print(f"  - {col}")
    print()
    
    predictions = []
    final_model = None
    
    with tqdm(total=len(df) - min_train_samples, desc="XGBoost í•™ìŠµ ë° ì˜ˆì¸¡") as pbar:
        for i in range(min_train_samples, len(df)):
            # Sliding Window ì ìš©
            if window_size is None:
                train_val_start = 0
            else:
                train_val_start = max(0, i - window_size)

            available_samples = i - train_val_start
            train_size_relative = int(available_samples * xgb_config['train_val_split'])
            train_end = train_val_start + train_size_relative
            
            X_train = df.iloc[train_val_start:train_end][feature_columns]
            y_train = df.iloc[train_val_start:train_end]['direction']
            
            X_val = df.iloc[train_end:i][feature_columns]
            y_val = df.iloc[train_end:i]['direction']
            
            X_test = df.iloc[i:i+1][feature_columns]
            y_test = df.iloc[i:i+1]['direction'].values[0]

            n_positive = (y_train == 1).sum()
            n_negative = (y_train == 0).sum()
            scale_pos_weight = n_negative / n_positive if n_positive > 0 else 1

            xgb_params = {
                'objective': xgb_config['objective'],
                'max_depth': xgb_config['max_depth'],
                'learning_rate': xgb_config['learning_rate'],
                'n_estimators': xgb_config['n_estimators'],
                'min_child_weight': xgb_config['min_child_weight'],
                'subsample': xgb_config['subsample'],
                'colsample_bytree': xgb_config['colsample_bytree'],
                'gamma': xgb_config['gamma'],
                'reg_alpha': xgb_config['reg_alpha'],
                'reg_lambda': xgb_config['reg_lambda'],
                'scale_pos_weight': scale_pos_weight,
                'random_state': xgb_config['random_state'],
                'verbosity': 0
            }

            early_stopping_rounds = xgb_config.get('early_stopping_rounds')

            if len(X_val) > 0 and early_stopping_rounds is not None:
                xgb_params['early_stopping_rounds'] = early_stopping_rounds
                xgb_model = XGBClassifier(**xgb_params)
                xgb_model.fit(
                    X_train,
                    y_train,
                    eval_set=[(X_train, y_train), (X_val, y_val)],
                    verbose=False,
                )
            else:
                xgb_model = XGBClassifier(**xgb_params)
                xgb_model.fit(X_train, y_train)
            
            final_model = xgb_model
            
            y_pred = xgb_model.predict(X_test)[0]
            y_pred_proba = xgb_model.predict_proba(X_test)[0]
            
            train_acc = accuracy_score(y_train, xgb_model.predict(X_train))
            val_acc = (
                accuracy_score(y_val, xgb_model.predict(X_val))
                if len(X_val) > 0
                else 0.0
            )

            result = {
                'ds': df.iloc[i]['ds'],
                'y': df.iloc[i]['y'],
                'y_actual_direction': y_test,
                'y_pred_direction': y_pred,
                'pred_proba_down': y_pred_proba[0],
                'pred_proba_up': y_pred_proba[1],
                'train_accuracy': train_acc,
                'val_accuracy': val_acc,
                'n_estimators_used': xgb_model.get_booster().num_boosted_rounds(),
                'train_size': len(X_train),
                'val_size': len(X_val),
                'scale_pos_weight': scale_pos_weight,
            }

            for col in feature_columns:
                result[col] = df.iloc[i][col]
            
            predictions.append(result)
            pbar.update(1)
    
    results_df = pd.DataFrame(predictions)
    print(f"âœ… XGBoost ì˜ˆì¸¡ ì™„ë£Œ: {len(results_df)} í–‰")
    
    return results_df, final_model


def calculate_metrics(results_df):
    """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
    y_true = results_df['y_actual_direction'].values
    y_pred = results_df['y_pred_direction'].values
    
    metrics = {
        'test_accuracy': accuracy_score(y_true, y_pred) * 100,
        'test_precision': precision_score(y_true, y_pred, zero_division=0) * 100,
        'test_recall': recall_score(y_true, y_pred, zero_division=0) * 100,
        'test_f1_score': f1_score(y_true, y_pred, zero_division=0) * 100,
    }
    
    # Train/Val ì •í™•ë„ í‰ê· 
    if 'train_accuracy' in results_df.columns:
        metrics['train_accuracy_mean'] = results_df['train_accuracy'].mean() * 100
    if 'val_accuracy' in results_df.columns:
        metrics['val_accuracy_mean'] = results_df['val_accuracy'].mean() * 100
    
    # ê³¼ì í•© ê°­
    if "train_accuracy" in results_df.columns:
        metrics["overfit_gap"] = (
            metrics["train_accuracy_mean"] - metrics["test_accuracy"]
        )

    # í‰ê·  ì‚¬ìš© íŠ¸ë¦¬
    if 'n_estimators_used' in results_df.columns:
        metrics['avg_n_estimators_used'] = results_df['n_estimators_used'].mean()
    
    return metrics


def analyze_feature_importance(model, feature_columns, top_n=20):
    print("ğŸ” Feature Importance ë¶„ì„")

    importances = model.feature_importances_

    importance_df = pd.DataFrame(
        {"feature": feature_columns, "importance": importances}
    ).sort_values("importance", ascending=False)

    total_importance = importance_df["importance"].sum()
    importance_df["importance_pct"] = (
        importance_df["importance"] / total_importance
    ) * 100
    importance_df["cumulative_pct"] = importance_df["importance_pct"].cumsum()

    # ìƒìœ„ Nê°œ ì¶œë ¥
    print(f"\nìƒìœ„ {min(top_n, len(importance_df))}ê°œ ì¤‘ìš” Features:")
    print("-" * 70)
    print(f"{'ìˆœìœ„':<6} {'Feature':<30} {'ì¤‘ìš”ë„':<12} {'ë¹„ìœ¨':<10} {'ëˆ„ì ':<10}")
    print("-" * 70)
    
    for idx, row in importance_df.head(top_n).iterrows():
        rank = importance_df.index.get_loc(idx) + 1
        print(f"{rank:<6} {row['feature']:<30} {row['importance']:<12.6f} {row['importance_pct']:>8.2f}% {row['cumulative_pct']:>8.2f}%")
    
    # ìƒìœ„ 80% ì¤‘ìš”ë„ë¥¼ ì°¨ì§€í•˜ëŠ” feature ê°œìˆ˜
    n_80pct = (importance_df['cumulative_pct'] <= 80).sum()
    print(f"\nğŸ’¡ ìƒìœ„ {n_80pct}ê°œ featureê°€ ì „ì²´ ì¤‘ìš”ë„ì˜ 80%ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤.")
    
    # ì¤‘ìš”ë„ íƒ€ì…ë³„ ë¶„ì„
    print("\n" + "=" * 70)
    print("ğŸ“Š ì¤‘ìš”ë„ ìƒì„¸ ë¶„ì„")
    print("=" * 70)
    
    try:
        # get_score()ë¡œ ë‹¤ì–‘í•œ ì¤‘ìš”ë„ ì§€í‘œ í™•ì¸
        booster = model.get_booster()
        
        # weight: í•´ë‹¹ featureê°€ íŠ¸ë¦¬ ë¶„í• ì— ì‚¬ìš©ëœ íšŸìˆ˜
        score_weight = booster.get_score(importance_type='weight')
        # gain: í•´ë‹¹ featureë¡œ ë¶„í• í•  ë•Œ í‰ê·  gain(ì†ì‹¤ ê°ì†ŒëŸ‰)
        score_gain = booster.get_score(importance_type='gain')
        # cover: í•´ë‹¹ featureê°€ ì»¤ë²„í•˜ëŠ” ìƒ˜í”Œ ìˆ˜
        score_cover = booster.get_score(importance_type='cover')
        
        print("\nì¤‘ìš”ë„ ê³„ì‚° ë°©ì‹ ë¹„êµ (ìƒìœ„ 5ê°œ):")
        print("-" * 70)
        
        for i, row in importance_df.head(5).iterrows():
            feat = row['feature']
            # XGBoost ë‚´ë¶€ì—ì„œëŠ” f0, f1, ... í˜•ì‹ìœ¼ë¡œ ì €ì¥ë¨
            feat_idx = f"f{feature_columns.index(feat)}"
            
            print(f"\n{i+1}. {feat}")
            print(f"   - Default (gain):  {row['importance']:.6f}")
            if feat_idx in score_weight:
                print(f"   - Weight (íšŸìˆ˜):   {score_weight[feat_idx]:.0f}")
            if feat_idx in score_gain:
                print(f"   - Gain (ì†ì‹¤ê°ì†Œ): {score_gain[feat_idx]:.6f}")
            if feat_idx in score_cover:
                print(f"   - Cover (ìƒ˜í”Œìˆ˜):  {score_cover[feat_idx]:.0f}")
    
    except Exception as e:
        print(f"\nâš ï¸  ìƒì„¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return importance_df


def analyze_yearly_performance(results_df):
    """ì—°ë„ë³„ ì„±ëŠ¥ ë¶„ì„"""
    # ì—°ë„ ì¶”ì¶œ
    results_df['year'] = pd.to_datetime(results_df['ds']).dt.year
    
    yearly_stats = []
    for year in sorted(results_df['year'].unique()):
        year_data = results_df[results_df['year'] == year]
        y_true = year_data['y_actual_direction'].values
        y_pred = year_data['y_pred_direction'].values
        
        accuracy = accuracy_score(y_true, y_pred) * 100
        count = len(year_data)

        yearly_stats.append(
            {
                "year": year,
                "accuracy": accuracy,
                "count": count,
                "correct": (y_true == y_pred).sum(),
            }
        )

    return pd.DataFrame(yearly_stats)


def print_results(results_df, metrics, config):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "=" * 70)
    print("ğŸ“Š XGBoost ë¶„ë¥˜ ì„±ëŠ¥ ì§€í‘œ")
    print("=" * 70)
    
    # Test ì„±ëŠ¥
    print("\n[Test ì„±ëŠ¥]")
    print(f"  Accuracy:  {metrics['test_accuracy']:.2f}%")
    print(f"  Precision: {metrics['test_precision']:.2f}%")
    print(f"  Recall:    {metrics['test_recall']:.2f}%")
    print(f"  F1-Score:  {metrics['test_f1_score']:.2f}%")
    
    # Train/Val ì„±ëŠ¥
    if 'train_accuracy_mean' in metrics:
        print("\n[Train/Val ì„±ëŠ¥]")
        print(f"  Train Accuracy (í‰ê· ): {metrics['train_accuracy_mean']:.2f}%")
        if 'val_accuracy_mean' in metrics:
            print(f"  Val Accuracy (í‰ê· ):   {metrics['val_accuracy_mean']:.2f}%")
        if 'overfit_gap' in metrics:
            gap = metrics['overfit_gap']
            print(f"  Overfit Gap:           {gap:+.2f}%p", end="")
            if gap > 10:
                print("  âš ï¸  ê³¼ì í•© ì˜ì‹¬!")
            elif gap > 5:
                print("  âš ï¸  ì•½ê°„ ê³¼ì í•©")
            else:
                print("  âœ… ì •ìƒ")
    
    # ëª¨ë¸ ì •ë³´
    if "avg_n_estimators_used" in metrics:
        print("\n[ëª¨ë¸ ì •ë³´]")
        print(
            f"  í‰ê·  ì‚¬ìš© íŠ¸ë¦¬ ê°œìˆ˜: {metrics['avg_n_estimators_used']:.1f}/{config['xgboost']['n_estimators']}"
        )

    # í˜¼ë™ í–‰ë ¬
    y_true = results_df['y_actual_direction'].values
    y_pred = results_df['y_pred_direction'].values
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ í˜¼ë™ í–‰ë ¬")
    print("=" * 70)
    
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nì‹¤ì œ í•˜ë½(0) / ì˜ˆì¸¡ í•˜ë½(0): {cm[0][0]}")
    print(f"ì‹¤ì œ í•˜ë½(0) / ì˜ˆì¸¡ ìƒìŠ¹(1): {cm[0][1]}")
    print(f"ì‹¤ì œ ìƒìŠ¹(1) / ì˜ˆì¸¡ í•˜ë½(0): {cm[1][0]}")
    print(f"ì‹¤ì œ ìƒìŠ¹(1) / ì˜ˆì¸¡ ìƒìŠ¹(1): {cm[1][1]}")
    
    print("\n" + "=" * 70)
    print("ğŸ“ˆ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸")
    print("=" * 70)
    print(
        "\n"
        + classification_report(
            y_true, y_pred, target_names=["í•˜ë½(0)", "ìƒìŠ¹(1)"], digits=4
        )
    )

    # ì—°ë„ë³„ ì„±ëŠ¥ ë¶„ì„
    print("\n" + "=" * 70)
    print("ğŸ“… ì—°ë„ë³„ ì„±ëŠ¥ ë¶„ì„")
    print("=" * 70)
    
    yearly_df = analyze_yearly_performance(results_df)

    print(
        f"\n{'ì—°ë„':<8} {'ì •í™•ë„':<12} {'ì˜ˆì¸¡ íšŸìˆ˜':<12} {'ì •ë‹µ íšŸìˆ˜':<12} {'íŠ¸ë Œë“œ':<10}"
    )
    print("-" * 70)
    
    for idx, row in yearly_df.iterrows():
        year = int(row['year'])
        acc = row['accuracy']
        count = int(row['count'])
        correct = int(row['correct'])
        
        # íŠ¸ë Œë“œ í‘œì‹œ
        if idx > 0:
            prev_acc = yearly_df.iloc[idx-1]['accuracy']
            diff = acc - prev_acc
            if diff > 2:
                trend = f"â†—ï¸ +{diff:.1f}%"
            elif diff < -2:
                trend = f"â†˜ï¸ {diff:.1f}%"
            else:
                trend = "â†’ ìœ ì‚¬"
        else:
            trend = "-"

        print(
            f"{year:<8} {acc:>7.2f}%    {count:>8}ê°œ    {correct:>8}ê°œ    {trend:<10}"
        )

    # ì´ˆë°˜/í›„ë°˜ ë¹„êµ
    if len(yearly_df) >= 2:
        print("\n" + "-" * 70)
        n_years = len(yearly_df)
        split_point = n_years // 2
        
        early_years = yearly_df.iloc[:split_point]
        late_years = yearly_df.iloc[split_point:]

        early_acc = early_years["correct"].sum() / early_years["count"].sum() * 100
        late_acc = late_years["correct"].sum() / late_years["count"].sum() * 100

        early_period = (
            f"{int(early_years.iloc[0]['year'])}~{int(early_years.iloc[-1]['year'])}"
        )
        late_period = (
            f"{int(late_years.iloc[0]['year'])}~{int(late_years.iloc[-1]['year'])}"
        )

        print(f"\nì´ˆë°˜ ({early_period}): {early_acc:.2f}%")
        print(f"í›„ë°˜ ({late_period}): {late_acc:.2f}%")
        
        diff = late_acc - early_acc
        if diff > 2:
            print(f"\nğŸ’¡ í›„ë°˜ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ì„±ëŠ¥ í–¥ìƒ! (+{diff:.2f}%p)")
        elif diff < -2:
            print(f"\nâš ï¸  í›„ë°˜ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ì„±ëŠ¥ ì €í•˜... ({diff:.2f}%p)")
        else:
            print(f"\nâ†’ ì´ˆë°˜ê³¼ í›„ë°˜ ì„±ëŠ¥ ë¹„ìŠ·í•¨ ({diff:+.2f}%p)")
    
    # ìµœê³ /ìµœì € ì—°ë„
    if len(yearly_df) > 0:
        best_year = yearly_df.loc[yearly_df["accuracy"].idxmax()]
        worst_year = yearly_df.loc[yearly_df["accuracy"].idxmin()]

        print(
            f"\nâœ… ìµœê³  ì„±ëŠ¥: {int(best_year['year'])}ë…„ ({best_year['accuracy']:.2f}%)"
        )
        print(
            f"âŒ ìµœì € ì„±ëŠ¥: {int(worst_year['year'])}ë…„ ({worst_year['accuracy']:.2f}%)"
        )
        print(f"   ì„±ëŠ¥ í¸ì°¨: {best_year['accuracy'] - worst_year['accuracy']:.2f}%p")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("XGBoost ë¶„ë¥˜ ëª¨ë¸ ì‹¤í–‰")
    print("=" * 70)
    
    # 1. ì„¤ì • ë¡œë“œ
    config = load_config('config.yaml')
    print("âœ… ì„¤ì • ë¡œë“œ ì™„ë£Œ\n")
    
    # 2. Prophet features ë¡œë“œ
    df = load_prophet_features(config['data']['prophet_output_csv'])
    
    # Feature ì»¬ëŸ¼ ì •ì˜ (ë‚˜ì¤‘ì— importance ë¶„ì„ì— ì‚¬ìš©)
    feature_columns = [
        col
        for col in df.columns
        if col not in ["ds", "y", "direction", "y_change", "yhat_lower", "yhat_upper"]
    ]

    # 3. XGBoost í•™ìŠµ ë° ì˜ˆì¸¡ (ê²€ì¦ ë°©ì‹ì— ë”°ë¼)
    validation_mode = config['validation']['mode']
    
    if validation_mode == 'walk_forward':
        results_df, model = train_xgboost_walkforward(df, config)
    elif validation_mode == 'fixed_test':
        raise NotImplementedError("fixed_test ëª¨ë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. walk_forward ëª¨ë“œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” validation_mode: {validation_mode}")
    
    # 4. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = calculate_metrics(results_df)
    
    # 5. ê²°ê³¼ ì¶œë ¥
    print_results(results_df, metrics, config)
    
    # 6. Feature Importance ë¶„ì„
    importance_df = analyze_feature_importance(model, feature_columns, top_n=20)
    
    # 8. ëª¨ë¸ ì €ì¥
    if config['output']['save_model']:
        model_path = config['data']['model_output_pkl']
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    
    print("\n" + "=" * 70)
    print("âœ… XGBoost ì‘ì—… ì™„ë£Œ!")
    print("=" * 70)
    
    return results_df, model, importance_df


class TimeSeriesXGBoostInference:
    """
    BigQueryì—ì„œ ê°€ì ¸ì˜¨ DataFrameì„ ì‚¬ìš©í•˜ì—¬ Walk-Forward ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ëŠ” í´ë˜ìŠ¤
    inference.pyì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    def __init__(self, config_path=None):
        """
        ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            config_path (str, optional): config.yaml íŒŒì¼ ê²½ë¡œ. Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©.
        """
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        self.config = load_config(config_path)
        self.xgb_config = self.config['xgboost']
        self.validation_config = self.config['validation']
        
    def predict(self, history_df: pd.DataFrame, target_date: str) -> Dict[str, Any]:
        """
        ì œê³µëœ ê³¼ê±° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Walk-Forward ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì‹œì¥ ë°©í–¥ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            history_df (pd.DataFrame): Prophet í”¼ì²˜ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„.
                                    'ds' ì»¬ëŸ¼ê³¼ í•™ìŠµì— ì‚¬ìš©ëœ ëª¨ë“  í”¼ì²˜ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                                    target_dateë¥¼ í¬í•¨í•œ ê³¼ê±° ë°ì´í„°ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            target_date (str): ì˜ˆì¸¡í•  ë‚ ì§œ ë¬¸ìì—´ ('YYYY-MM-DD' í˜•ì‹).
            
        Returns:
            Dict: ì˜ˆì¸¡ ìƒì„¸ ê²°ê³¼ ì‚¬ì „ (inference.pyì™€ ë™ì¼í•œ í˜•ì‹).
        """
        try:
            target_ts = pd.Timestamp(target_date)
        except ValueError:
            raise ValueError(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {target_date}. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # 'ds' ì»¬ëŸ¼ì´ datetime í˜•ì‹ì¸ì§€ í™•ì¸
        if not pd.api.types.is_datetime64_any_dtype(history_df['ds']):
            history_df['ds'] = pd.to_datetime(history_df['ds'])
        
        # íƒ€ê²Ÿ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” í–‰ ì°¾ê¸°
        target_idx = history_df[history_df['ds'] == target_ts].index
        
        if len(target_idx) == 0:
            raise ValueError(f"ì œê³µëœ ë°ì´í„°í”„ë ˆì„ì—ì„œ í•´ë‹¹ ë‚ ì§œ({target_date})ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        target_idx = target_idx[0]
        target_row_idx = history_df.index.get_loc(target_idx)
        
        # í”¼ì²˜ ì»¬ëŸ¼ ì •ì˜
        exclude_cols = ['ds', 'y', 'direction', 'y_change', 'yhat_lower', 'yhat_upper']
        feature_columns = [col for col in history_df.columns if col not in exclude_cols]
        
        # Walk-Forward í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        min_train_samples = self.validation_config['min_train_samples']
        window_size = self.validation_config.get('window_size', None)
        train_val_split = self.xgb_config['train_val_split']
        
        # íƒ€ê²Ÿ ë‚ ì§œê¹Œì§€ì˜ ë°ì´í„°ë§Œ ì‚¬ìš© (ë¯¸ë˜ ë°ì´í„°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        df_until_target = history_df.iloc[:target_row_idx + 1].copy()
        
        if len(df_until_target) < min_train_samples:
            raise ValueError(
                f"í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜({min_train_samples})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. "
                f"í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒ˜í”Œ ìˆ˜: {len(df_until_target)}"
            )
        
        # Sliding Window ì ìš©
        if window_size is None:
            train_val_start = 0
        else:
            train_val_start = max(0, target_row_idx - window_size)
        
        available_samples = target_row_idx - train_val_start
        train_size_relative = int(available_samples * train_val_split)
        train_end = train_val_start + train_size_relative
        
        # Train/Val/Test ë¶„ë¦¬
        X_train = df_until_target.iloc[train_val_start:train_end][feature_columns]
        y_train = df_until_target.iloc[train_val_start:train_end]['direction']
        
        X_val = df_until_target.iloc[train_end:target_row_idx][feature_columns]
        y_val = df_until_target.iloc[train_end:target_row_idx]['direction']
        
        X_test = df_until_target.iloc[target_row_idx:target_row_idx+1][feature_columns]
        row = df_until_target.iloc[target_row_idx:target_row_idx+1]
        
        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        n_positive = (y_train == 1).sum()
        n_negative = (y_train == 0).sum()
        scale_pos_weight = n_negative / n_positive if n_positive > 0 else 1
        
        # XGBoost íŒŒë¼ë¯¸í„° ì„¤ì •
        xgb_params = {
            'objective': self.xgb_config['objective'],
            'max_depth': self.xgb_config['max_depth'],
            'learning_rate': self.xgb_config['learning_rate'],
            'n_estimators': self.xgb_config['n_estimators'],
            'min_child_weight': self.xgb_config['min_child_weight'],
            'subsample': self.xgb_config['subsample'],
            'colsample_bytree': self.xgb_config['colsample_bytree'],
            'gamma': self.xgb_config['gamma'],
            'reg_alpha': self.xgb_config['reg_alpha'],
            'reg_lambda': self.xgb_config['reg_lambda'],
            'scale_pos_weight': scale_pos_weight,
            'random_state': self.xgb_config['random_state'],
            'verbosity': 0
        }
        
        # ëª¨ë¸ í•™ìŠµ
        early_stopping_rounds = self.xgb_config.get('early_stopping_rounds')
        
        if len(X_val) > 0 and early_stopping_rounds is not None:
            xgb_params['early_stopping_rounds'] = early_stopping_rounds
            xgb_model = XGBClassifier(**xgb_params)
            xgb_model.fit(
                X_train, y_train,
                eval_set=[(X_train, y_train), (X_val, y_val)],
                verbose=False
            )
        else:
            xgb_model = XGBClassifier(**xgb_params)
            xgb_model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction_prob = xgb_model.predict_proba(X_test)[0]  # [í•˜ë½í™•ë¥ , ìƒìŠ¹í™•ë¥ ]
        prediction = xgb_model.predict(X_test)[0]  # 0 ë˜ëŠ” 1
        
        confidence = prediction_prob[1] if prediction == 1 else prediction_prob[0]
        
        # Prophet ì˜ˆì¸¡ê°’ (yhat)
        yhat = row['yhat'].values[0]
        
        # ë¬¸ë§¥ í†µê³„ (ì¶”ì„¸ ë¶„ì„ìš©)
        # ì œê³µëœ ê³¼ê±° ë°ì´í„°ì—ì„œ ìµœê·¼ 7ì¼ í‰ê·  ê³„ì‚°
        recent_7_days = df_until_target.tail(7)
        recent_mean = recent_7_days['yhat'].mean()
        
        # ì „ ê¸°ê°„ í‰ê·  ê³„ì‚°
        all_time_mean = df_until_target['yhat'].mean()
        
        # inference.pyì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ë°˜í™˜
        return {
            "target_date": target_date,
            "forecast_value": float(yhat),         # Prophet ì˜ˆì¸¡ê°’
            "forecast_direction": "Up" if prediction == 1 else "Down",
            "confidence_score": float(confidence) * 100,  # ì‹ ë¢°ë„ (%)
            "recent_mean_7d": float(recent_mean),  # ìµœê·¼ 7ì¼ í‰ê· 
            "all_time_mean": float(all_time_mean), # ì „ì²´ ê¸°ê°„ í‰ê· 
            "trend_analysis": "Rising" if yhat > recent_mean else "Falling",  # ë‹¨ìˆœ ì¶”ì„¸
            "volatility_index": float(recent_7_days['yhat'].std()),  # ë³€ë™ì„± ì§€í‘œ (í‘œì¤€í¸ì°¨)
            "last_observed_value": float(row['y'].values[0]) if 'y' in row.columns and not pd.isna(row['y'].values[0]) else None  # ì‹¤ì œê°’ (ìˆìœ¼ë©´)
        }


if __name__ == "__main__":
    results, model, importance = main()