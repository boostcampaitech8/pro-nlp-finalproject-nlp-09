from typing import Optional
from langchain_core.tools import tool
import subprocess
import json
from google.auth import default
from google.auth.transport.requests import Request
from langchain_core.messages import HumanMessage, AIMessage

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

from config.settings import (
    GENERATE_MODEL_NAME, GENERATE_MODEL_TEMPERATURE, GENERATE_MODEL_MAX_TOKENS,
    VERTEX_AI_PROJECT_ID, VERTEX_AI_LOCATION,
)
from models.timeseries_predictor import predict_market_trend
from models.sentiment_analyzer import SentimentAnalyzer


# ìƒìˆ˜ ì •ì˜
REPORT_FORMAT = """**ì¼ì¼ ê¸ˆìœµ ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œ **
> **ğŸ“… ë¶„ì„ ì¼ì ** : (YYYY-MM-DD)
> **ğŸ’¬ ì¢…í•© ì˜ê²¬ ** : [ì¢…í•© ì˜ê²¬ í•œì¤„ ìš”ì•½]
---

### 1. ğŸ“Š ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ê°€ ì˜ê²¬
> [ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ í•œì¤„ í‰ê°€]

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì…ë ¥ ë°ì´í„° ê¸¸ì´** | 5ë…„ (Prophet Features) |
| **ë§ˆì§€ë§‰ ê´€ì¸¡ê°’** | [Last Observed Value] |
| **ì‹œê³„ì—´ ì˜ˆì¸¡ê°’** | [Forecast Value] |
| **ì‹ ë¢°ë„** | [Confidence Score] % |

- **ì¶”ì„¸ ë¶„ì„**
  - **ìµœê·¼ ê¸°ê°„ í‰ê· ** (7ì¼) : [Recent Mean]
  - **ì „ ê¸°ê°„ í‰ê· ** : [All-time Mean]
  - **ìµœê·¼ ë³€ë™ ì¶”ì´** : [Trend Analysis: Rising/Falling ë“± ì„¤ëª…]
  - **ì‹œê³„ì—´ ì˜ˆì¸¡ê°’ í•´ì„** : [Forecast Direction] ë°©í–¥ìœ¼ë¡œ ì˜ˆì¸¡ë˜ë©°, ì‹ ë¢°ë„ëŠ” [Confidence Score]% ì…ë‹ˆë‹¤.

- **ì˜ˆì¸¡ê°’ í•´ì„**
  - **í˜„ì¬ ìˆ˜ì¤€ ëŒ€ë¹„** : [Last Value] ëŒ€ë¹„ [Forecast Value] ë¡œ ë³€ë™ ì˜ˆìƒ.
  - **ë‹¨ê¸° ë³€ë™ì„± í‰ê°€** : ë³€ë™ì„± ì§€í‘œ [Volatility Index] ìˆ˜ì¤€.

---

### 2. ğŸ“° ë‰´ìŠ¤ ê°ì„±ë¶„ì„ ê²°ê³¼ ë¶„ì„
> [ë‰´ìŠ¤ ê¸°ì‚¬ ê°ì„±ë¶„ì„ í•œì¤„ í‰ê°€]

| ê¸°ì‚¬ ë²ˆí˜¸ | ì œëª© | ì˜í–¥ë ¥ ì ìˆ˜ | ìš”ì•½ |
|-----------|------|-------------|------|
| 1 | [ê¸°ì‚¬ ì œëª©] | [ì ìˆ˜] | [ë‚´ìš© ìš”ì•½] |
| 2 | [ê¸°ì‚¬ ì œëª©] | [ì ìˆ˜] | [ë‚´ìš© ìš”ì•½] |
| ... | ... | ... | ... |

- **ì‹œì¥ ì˜í–¥ë ¥ ë¶„ì„**
  - **ìƒìŠ¹ í™•ë¥ **: [Probability] %
  - **ì¢…í•© ì˜ê²¬**: [ë‰´ìŠ¤ ê¸°ë°˜ ìƒìŠ¹/í•˜ë½ ì˜ˆì¸¡ ì˜ê²¬]

- **í…ìŠ¤íŠ¸ì  ê·¼ê±°**
  - [ê° ê¸°ì‚¬ê°€ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„]
  - [ì£¼ìš” í‚¤ì›Œë“œ ë° ê´€ê³„ ì •ë³´(Triple) í™œìš©]

---

### 3. ë¯¸ë˜ ì‹œì¥ ì „ë§

| êµ¬ë¶„ | ê·¼ê±° | ì „ë§ |
|------|------|------|
| **ë‹¨ê¸°(1â€“3ì¼)** | [ì‹œê³„ì—´ ì˜ˆì¸¡ ê²°ê³¼ ë° ë‰´ìŠ¤ ë‹¨ê¸° ì˜í–¥] | **[ì „ë§]** [ìƒì„¸ ì„¤ëª…] |
| **ì¤‘ê¸°(1ì£¼)** | [ë‰´ìŠ¤ íŠ¸ë Œë“œ ë° ì¤‘ê¸° ì´ìŠˆ] | **[ì „ë§]** [ìƒì„¸ ì„¤ëª…] |
| **ì¥ê¸°(1ê°œì›”)** | [ê±°ì‹œ ê²½ì œ ë° ì •ì±… ë‰´ìŠ¤] | **[ì „ë§]** [ìƒì„¸ ì„¤ëª…] |

- **ìœ„í—˜ ìš”ì¸**
  - [ì£¼ìš” ìœ„í—˜ ìš”ì¸ ë‚˜ì—´]

- **ê¸°íšŒ ìš”ì¸**
  - [ì£¼ìš” ê¸°íšŒ ìš”ì¸ ë‚˜ì—´]

---

### 4. ì¢…í•© ì˜ê²¬

- **[í˜„ì¬ ì‹œì¥ ìƒí™© ìš”ì•½]**
- **[ì£¼ìš” ì§€í‘œ ë° ë‰´ìŠ¤ ìš”ì•½]**
- **[ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ì „ë§ ìš”ì•½]**
- **[íˆ¬ìì ì…ì¥ì—ì„œì˜ ì¡°ì–¸]**

**ê²°ë¡ **: [ë‚ ì§œ] ê¸°ì¤€, ì‹œì¥ì€ **[ì „ë§]**ì„ ìœ ì§€í•  ê²ƒìœ¼ë¡œ ì „ë§ë˜ë©°, **[ì£¼ìš” ì„±ì¥ ë™ë ¥]**ì´ ì£¼ìš” ì„±ì¥ ë™ë ¥ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ **[ì£¼ìš” ë¦¬ìŠ¤í¬]**ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ë¥¼ ì£¼ì˜ ê¹Šê²Œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•©ë‹ˆë‹¤.

**ì¤‘ìš”**: 
- ë°˜ë“œì‹œ ìœ„ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
- í‘œ í˜•ì‹ì€ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ì„¹ì…˜ ë²ˆí˜¸ì™€ ì œëª©ì€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
- ê° ì„¹ì…˜ì€ "---"ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
- ì–¸ì–´ëŠ” ë°˜ë“œì‹œ ìˆœìˆ˜ í•œêµ­ì–´(í•œê¸€)ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."""

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬**:
1. timeseries_predictor: ì‹œê³„ì—´ ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì˜ˆì¸¡
   - target_date: ë¶„ì„í•  ëŒ€ìƒ ë‚ ì§œ (í˜•ì‹: "YYYY-MM-DD")
   - ì„¤ëª…: ì§€ì •ëœ ë‚ ì§œì˜ ê°€ê²© ì¶”ì„¸, ì˜ˆì¸¡ê°’, ì‹ ë¢°ë„ ë“±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

2. news_sentiment_analyzer: ë‰´ìŠ¤ ê¸°ë°˜ ì‹œì¥ ì˜í–¥ë ¥ ë¶„ì„ ë° ê·¼ê±° ì¶”ì¶œ
   - target_date: ë¶„ì„í•  ëŒ€ìƒ ë‚ ì§œ (í˜•ì‹: "YYYY-MM-DD")
   - ì„¤ëª…: í•´ë‹¹ ë‚ ì§œ ì „í›„ì˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œì¥ ìƒìŠ¹/í•˜ë½ í™•ë¥ ì„ ì˜ˆì¸¡í•˜ê³ , ì˜ˆì¸¡ì˜ í•µì‹¬ ê·¼ê±°ê°€ ëœ ì£¼ìš” ë‰´ìŠ¤ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

**ë„êµ¬ ì‚¬ìš© ê·œì¹™**:
- ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ(target_date)ê°€ ì£¼ì–´ì§€ë©´ ë°˜ë“œì‹œ ë‘ ë„êµ¬(`timeseries_predictor`, `news_sentiment_analyzer`)ë¥¼ ëª¨ë‘ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ í™•ë³´í•˜ì„¸ìš”.
- `news_sentiment_analyzer` ê²°ê³¼ì— í¬í•¨ëœ 'evidence_news'ëŠ” ë³´ê³ ì„œì˜ '### 2. ğŸ“° ë‰´ìŠ¤ ê°ì„±ë¶„ì„ ê²°ê³¼ ë¶„ì„' ì„¹ì…˜ì˜ í•µì‹¬ ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. ê° ë‰´ìŠ¤ì˜ ì œëª©ê³¼ ì‹œì¥ ì˜í–¥ë ¥ ì ìˆ˜(price_impact_score)ë¥¼ ë³´ê³ ì„œ í‘œì— í¬í•¨í•˜ì„¸ìš”.
- ë‘ ë„êµ¬ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë…¼ë¦¬ì ì¸ ê¸ˆìœµ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. ì‹œê³„ì—´ ì§€í‘œì™€ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ ì„œë¡œ ë³´ì™„ë˜ë„ë¡ ì„œìˆ í•˜ì„¸ìš”.

**ë³´ê³ ì„œ ì‘ì„± í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤)**:

""" + REPORT_FORMAT


# LangChain Tools ì •ì˜
@tool
def timeseries_predictor(target_date: str) -> str:
    """
    íŠ¹ì • ë‚ ì§œì˜ ê¸ˆìœµ ì‹œì¥ ì¶”ì„¸(ìƒìŠ¹/í•˜ë½)ì™€ ê°€ê²©ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    
    Args:
        target_date: ë¶„ì„í•  ë‚ ì§œ ë¬¸ìì—´ (í˜•ì‹: "YYYY-MM-DD")
    
    Returns:
        JSON í˜•ì‹ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¬¸ìì—´ (ì˜ˆì¸¡ê°’, ë°©í–¥, ì‹ ë¢°ë„, ì¶”ì„¸ ë¶„ì„ ë“± í¬í•¨)
    """
    return predict_market_trend(target_date)


@tool
def news_sentiment_analyzer(target_date: str) -> str:
    """
    íŠ¹ì • ë‚ ì§œì˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œì¥ ì˜í–¥ë ¥ì„ ì˜ˆì¸¡í•˜ê³  ì£¼ìš” ê·¼ê±° ë‰´ìŠ¤(ì œëª©, ì˜í–¥ë ¥ ì ìˆ˜, ê´€ê³„ ì •ë³´ ë“±)ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        target_date: ë¶„ì„í•  ë‚ ì§œ ë¬¸ìì—´ (í˜•ì‹: "YYYY-MM-DD")
    
    Returns:
        JSON í˜•ì‹ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¬¸ìì—´ (ìƒìŠ¹ í™•ë¥ , ê·¼ê±° ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸, í”¼ì²˜ ìš”ì•½ í¬í•¨)
    """
    analyzer = SentimentAnalyzer()
    result = analyzer.predict_market_impact(target_date)
    return json.dumps(result, ensure_ascii=False)


class LLMSummarizer:
    """Vertex AIë¥¼ ì‚¬ìš©í•˜ëŠ” LangChain Agentë¥¼ ì´ìš©í•œ í†µí•© ë¶„ì„"""
    
    def __init__(
        self, 
        model_name: str = None,
        project_id: str = None,
        location: str = None
    ):
        """
        Args:
            model_name: ìƒì„± ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: ì„¤ì • íŒŒì¼ì˜ GENERATE_MODEL_NAME)
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì„¤ì • íŒŒì¼ ë˜ëŠ” gcloud configì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´)
            location: Vertex AI ë¦¬ì „ (ê¸°ë³¸ê°’: ì„¤ì • íŒŒì¼ì˜ VERTEX_AI_LOCATION)
        """
        self.model_name = model_name or GENERATE_MODEL_NAME
        self.project_id = project_id or VERTEX_AI_PROJECT_ID or self._get_project_id()
        self.location = location or VERTEX_AI_LOCATION
        self.llm = None
        self.agent = None
        self._initialize()
    
    def _get_project_id(self) -> str:
        """gcloud configì—ì„œ í”„ë¡œì íŠ¸ IDë¥¼ ê°€ì ¸ì˜´"""
        try:
            result = subprocess.run(
                ["gcloud", "config", "get-value", "project"],
                capture_output=True,
                text=True,
                timeout=2
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
            else:
                raise ValueError("gcloud configì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            raise ValueError(
                f"project_idê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                f"í•´ê²° ë°©ë²•: gcloud config set project YOUR_PROJECT_ID\n"
                f"ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ GOOGLE_CLOUD_PROJECTë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n"
                f"ì˜¤ë¥˜: {e}"
            )
    
    def _get_access_token(self) -> str:
        """Google Cloud ì¸ì¦ í† í° ê°€ì ¸ì˜¤ê¸°"""
        credentials, _ = default(scopes=["https://www.googleapis.com/auth/cloud-platform"])
        if not credentials.valid:
            credentials.refresh(Request())
        return credentials.token
    
    def _build_base_url(self) -> str:
        """Vertex AI OpenAI í˜¸í™˜ API base URL ìƒì„±"""
        return (
            f"https://{self.location}-aiplatform.googleapis.com/v1/"
            f"projects/{self.project_id}/locations/{self.location}/endpoints/openapi"
        )
    
    def _create_llm(self, access_token: str) -> ChatOpenAI:
        """ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return ChatOpenAI(
            model=self.model_name,
            base_url=self._build_base_url(),
            api_key=access_token,
            temperature=GENERATE_MODEL_TEMPERATURE,
            max_tokens=GENERATE_MODEL_MAX_TOKENS,
            model_kwargs={
                "parallel_tool_calls": False,
            },
        )
    
    
    def _initialize(self):
        """LLM ë° Agent ì´ˆê¸°í™”"""
        access_token = self._get_access_token()
        self.llm = self._create_llm(access_token)
        print(f"âœ… ChatOpenAI (Vertex AI OpenAI í˜¸í™˜ API) ì‚¬ìš©: {self.model_name}")
        
        tools = [
            timeseries_predictor,
            news_sentiment_analyzer
        ]
        llm_with_tools = self.llm.bind_tools(tools)
        
        self.agent = create_agent(
            model=llm_with_tools,
            tools=tools,
            system_prompt=SYSTEM_PROMPT,
        )
    
    def _build_user_input(
        self,
        context: str,
        target_date: str,
    ) -> str:
        """Agentì—ê²Œ ì „ë‹¬í•  ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ ìƒì„±"""
        
        user_input = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ê¸ˆìœµ ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ë§¥ë½**: {context or "ìµœê·¼ ì‹œì¥ ìƒí™© ë¶„ì„"}
**ë¶„ì„ ê¸°ì¤€ ì¼ì**: {target_date}

- `timeseries_predictor`ì™€ `news_sentiment_analyzer` ë„êµ¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ {target_date}ì˜ ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
"""
        return user_input
    
    def _validate_output_format(self, summary: str) -> bool:
        """ì¶œë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦ (ìµœì†Œ ê²€ì¦)
        
        Returns:
            bool: í˜•ì‹ì´ ì˜¬ë°”ë¥´ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False
        """
        # ìµœì†Œí•œì˜ ê¸¸ì´ í™•ì¸
        if not summary or len(summary.strip()) < 100:
            return False
        
        return True
    
    def _extract_summary_from_result(self, result: dict) -> str:
        """Agent ì‹¤í–‰ ê²°ê³¼ì—ì„œ ìš”ì•½ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        import json
        messages = result.get("messages", [])
        
        # messagesì—ì„œ ë§ˆì§€ë§‰ AIMessageì˜ content ì¶”ì¶œ
        for msg in reversed(messages):
            if isinstance(msg, AIMessage):
                content = str(msg.content) if msg.content else ""
                content = content.strip().rstrip('\\')
                
                # JSON í˜•ì‹ì˜ tool call argumentsëŠ” ê±´ë„ˆë›°ê¸°
                if content.startswith("{{") and content.strip().endswith("}}"):
                    try:
                        # JSON íŒŒì‹± ì‹œë„
                        parsed = json.loads(content)
                        # tool call arguments í˜•ì‹ì¸ì§€ í™•ì¸ (texts, data ë“±ì˜ í‚¤ê°€ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°)
                        if isinstance(parsed, dict) and any(key in parsed for key in ["texts", "data", "target_date"]):
                            continue
                    except (json.JSONDecodeError, ValueError):
                        # JSONì´ ì•„ë‹ˆë©´ ê³„ì† ì§„í–‰
                        pass
                
                # GPT-OSS-20B íŠ¹ìˆ˜ í˜•ì‹ ì œê±° (<|channel|> ë“±)
                # tool calling í˜•ì‹ì¸ ê²½ìš° ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                if content.startswith("<|channel|>") and "<|call|>" in content:
                    # tool calling í˜•ì‹ì´ê³  ì‹¤ì œ ë³´ê³ ì„œ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                    if not any(keyword in content for keyword in ["ë³´ê³ ì„œ", "ë¶„ì„", "ì˜ê²¬", "ì „ë§", "ì‹œì¥"]):
                        continue
                
                if content and len(content) > 50:  # ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ
                    return content
        
        # messagesì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° output í•„ë“œ í™•ì¸
        output = result.get("output") or result.get("final_output")
        if output:
            return str(output).strip().rstrip('\\')
        
        # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ ì „ì²´ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        return str(result).strip().rstrip('\\')
    
    def summarize(
        self,
        context: str = "",
        target_date: Optional[str] = None,
        max_retries: int = 2,
    ) -> dict:
        """LangChain Agentë¥¼ ì´ìš©í•œ LLM ìš”ì•½ ìƒì„±
        
        Args:
            context: ë¶„ì„ ë§¥ë½
            target_date: ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ (YYYY-MM-DD)
            max_retries: ì¬ì‹œë„ íšŸìˆ˜
        """
        # ë‚ ì§œ ê¸°ë³¸ê°’ (ì˜¤ëŠ˜)
        if not target_date:
            from datetime import datetime
            target_date = datetime.now().strftime("%Y-%m-%d")
            
        user_input = self._build_user_input(
            context=context,
            target_date=target_date
        )
        
        for attempt in range(max_retries + 1):
            # Agent ì‹¤í–‰ (LangChainì´ ìë™ìœ¼ë¡œ tool callì„ ì²˜ë¦¬í•¨)
            if attempt == 0:
                result = self.agent.invoke({
                    "messages": [HumanMessage(content=user_input)]
                })
            else:
                # ì¬ì‹œë„ ì‹œ ê¸°ì¡´ ë©”ì‹œì§€ ì‚¬ìš©
                result = self.agent.invoke({
                    "messages": result.get('messages', [])
                })
            
            # ê²°ê³¼ ì¶”ì¶œ
            if isinstance(result, dict):
                messages = result.get('messages', [])
                
                summary = self._extract_summary_from_result(result)
                agent_result = result
                
                # ë””ë²„ê¹…: ë©”ì‹œì§€ ìƒíƒœ í™•ì¸
                print(f"\n[ë””ë²„ê¹…] ì´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
                tool_call_count = sum(1 for msg in messages if isinstance(msg, AIMessage) and msg.tool_calls)
                tool_result_count = sum(1 for msg in messages if hasattr(msg, 'name') and msg.name)
                print(f"  Tool í˜¸ì¶œ: {tool_call_count}íšŒ, Tool ê²°ê³¼: {tool_result_count}ê°œ")
            else:
                summary = str(result).strip().rstrip('\\')
                agent_result = {'messages': []}
            
            # ìš”ì•½ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš° í™•ì¸
            if not summary or len(summary.strip()) < 50:
                print(f"\nâš ï¸ ìš”ì•½ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ê¸¸ì´: {len(summary)}ì)")
                # ë§ˆì§€ë§‰ AIMessageì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì°¾ê¸°
                if isinstance(result, dict):
                    messages = result.get('messages', [])
                    for msg in reversed(messages):
                        if isinstance(msg, AIMessage) and msg.content:
                            content = str(msg.content)
                            # GPT-OSS-20B íŠ¹ìˆ˜ í˜•ì‹ì´ ì•„ë‹Œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì°¾ê¸°
                            if "<|channel|>" not in content and len(content.strip()) > 50:
                                summary = content.strip()
                                print(f"  â†’ ëŒ€ì²´ í…ìŠ¤íŠ¸ ë°œê²¬ (ê¸¸ì´: {len(summary)}ì)")
                                break
            
            # ì¶œë ¥ í˜•ì‹ ê²€ì¦
            if summary and len(summary.strip()) > 50 and self._validate_output_format(summary):
                return {
                    'summary': summary or '',
                    'agent_result': agent_result,
                }
            
            # í˜•ì‹ì´ ë§ì§€ ì•Šìœ¼ë©´ ì¬ì‹œë„
            if attempt < max_retries:
                print(f"\nâš ï¸ ì¶œë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                print(f"í˜„ì¬ ìš”ì•½ ê¸¸ì´: {len(summary)}ì")
                if summary:
                    print(f"ìš”ì•½ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):\n{summary[:500]}...\n")
                
                user_input = f"""{user_input}

**ì¤‘ìš”**: ì´ì „ ì‘ë‹µì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”:

{REPORT_FORMAT}

**íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”**:
1. ì„¹ì…˜ ì œëª©ì´ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤: "### 1. ğŸ“Š ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ê°€ ì˜ê²¬", "### 2. ğŸ“° ë‰´ìŠ¤ ê°ì„±ë¶„ì„ ê²°ê³¼ ë¶„ì„", "### 3. ë¯¸ë˜ ì‹œì¥ ì „ë§", "### 4. ì¢…í•© ì˜ê²¬"
2. ê° ì„¹ì…˜ì€ "---"ë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (ìµœì†Œ 3ê°œ)
3. ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹(|)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
4. í—¤ë”ì— "ğŸ“… ë¶„ì„ ì¼ì"ì™€ "ğŸ’¬ ì¢…í•© ì˜ê²¬"ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
5. Tool í˜¸ì¶œ í›„ ë°˜ë“œì‹œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤"""
            else:
                print("\nâš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜•ì‹ì´ ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                print(f"ìµœì¢… ìš”ì•½ ê¸¸ì´: {len(summary)}ì")
                if summary:
                    print(f"ìš”ì•½ ë¯¸ë¦¬ë³´ê¸°: {summary[:200]}...")
                print("ê²€ì¦ì„ í†µê³¼í•˜ì§€ ëª»í–ˆì§€ë§Œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        
        return {
            'summary': summary or '',
            'agent_result': agent_result,
        }
