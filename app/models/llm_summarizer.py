from typing import Optional, Tuple, Union, Dict, Any, List
from langchain_core.tools import tool
import subprocess
import json
import os
import sys
from datetime import datetime, timedelta
from langchain_core.messages import HumanMessage, AIMessage

from langchain.agents import create_agent
from langchain_google_vertexai import ChatVertexAI

from config.settings import (
    GENERATE_MODEL_NAME,
    GENERATE_MODEL_TEMPERATURE,
    GENERATE_MODEL_MAX_TOKENS,
    VERTEX_AI_PROJECT_ID,
    VERTEX_AI_LOCATION,
)
from models.timeseries_predictor import predict_market_trend
from models.sentiment_analyzer import SentimentAnalyzer
from models.keyword_analyzer import analyze_keywords as _analyze_keywords
from models.pastnews_rag_runner import run_pastnews_rag as _run_pastnews_rag


REPORT_FORMAT = """
**ë‚ ì§œ**: (YYYY-MM-DD) | **ì¢…ëª©**: [ë¶„ì„ ëŒ€ìƒ í’ˆëª©ëª…] 

| ì–´ì œ ì¢…ê°€ | Prophet ì˜ˆì¸¡ | XGBoost ë°©í–¥ | ì¢…í•© ì˜ê²¬ |
|:---:|:---:|:---:|:---:|
| [y] | [yhat] | [forecast_direction] | [BUY/SELL/HOLD] |

---

### 1. ğŸ“ˆ [Quant] í€€íŠ¸ ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„

**A. ê°€ê²© ì˜ˆì¸¡**
* **ì–´ì œ ì¢…ê°€**: [y]
* **Prophet ì˜ˆì¸¡ê°’**: [yhat] 
* **XGBoost ë°©í–¥ ì˜ˆì¸¡**: [forecast_direction] (Up/Down)

**B. ì£¼ìš” ë³€ë™ ìš”ì¸**

**B-1. ì‹œê³„ì—´ ì„±ë¶„**

| ì§€í‘œ | ê°’ | í•´ì„ | ì„¤ëª… |
|------|-----|------|------|
| ì¶”ì„¸ (trend) | [ê°’] | [ìƒìŠ¹/íš¡ë³´/í•˜ë½] ì¶”ì„¸ | ì¶”ì„¸ ì§€í‘œ|
| ì—°ê°„ ì£¼ê¸° (yearly) | [ê°’] | [ê¸ì •ì /ë¶€ì •ì /ì¤‘ë¦½] ì˜í–¥ | ê³„ì ˆì  ìš”ì¸ìœ¼ë¡œ ì¸í•œ ì—°ê°„ íŒ¨í„´ |
| ì£¼ê°„ ì£¼ê¸° (weekly) | [ê°’] | [ê¸ì •ì /ë¶€ì •ì /ì¤‘ë¦½] ì˜í–¥ | ìš”ì¼ë³„ íŒ¨í„´ |
| ë³€ë™ì„± (volatility) | [ê°’] | [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ] ìˆ˜ì¤€ | ì‹œì¥ ë¶ˆí™•ì‹¤ì„± ì§€í‘œ |

**B-2. ê¸°ìˆ ì  ì§€í‘œ**

| ì§€í‘œ | ê°’ | í•´ì„ | ì„¤ëª… |
|------|-----|------|------|
| EMA (ì§€ìˆ˜ì´ë™í‰ê· ) | [ê°’] | [ìƒìŠ¹/í•˜ë½] ìš”ì¸ | EMA ì˜í–¥ ì§€í‘œ |
| Volume (ê±°ë˜ëŸ‰) | [ê°’] | [ìƒìŠ¹/í•˜ë½] ìš”ì¸ | ê±°ë˜ëŸ‰ ì˜í–¥ ì§€í‘œ |

**C. í€€íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ í•´ì„**

* **Prophet vs XGBoost ë¹„êµ**:
  - Prophet ì˜ˆì¸¡: [yhat] ([ìƒìŠ¹/í•˜ë½])
  - XGBoost ì˜ˆì¸¡: [forecast_direction] (Up/Down)
  - ì¼ì¹˜ ì—¬ë¶€: [ì¼ì¹˜/ë¶ˆì¼ì¹˜]

* **í•µì‹¬ ê·¼ê±° ë¶„ì„**:
  - **ì‹œê³„ì—´ ì„±ë¶„**: ì¶”ì„¸([trend], [ìƒìŠ¹/íš¡ë³´/í•˜ë½] ì¶”ì„¸), ì—°ê°„ì£¼ê¸°([yearly]), ì£¼ê°„ì£¼ê¸°([weekly]), ë³€ë™ì„±([volatility], [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ] ìˆ˜ì¤€)ì„ ì¢…í•©í•˜ë©´ [ë¶„ì„ ë‚´ìš©]
  - **ê¸°ìˆ ì  ì§€í‘œ**: ì§€ìˆ˜ì´ë™í‰ê· (EMA_lag2_effect: [ê°’])ê³¼ ê±°ë˜ëŸ‰(Volume_lag5_effect: [ê°’])ì€ [ìƒìŠ¹/í•˜ë½] ìš”ì¸ìœ¼ë¡œ ì‘ìš©
  - **ì¢…í•© íŒë‹¨**: Prophetì´ [yhat]ë¡œ ì˜ˆì¸¡í•˜ê³  XGBoostê°€ [forecast_direction]ì„ ì˜ˆì¸¡í•œ ì´ìœ ë¥¼ ìœ„ ìš”ì¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì„œìˆ . ë‹¨, ë³€ìˆ˜ëª…(EMA_lag2_effect ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ê³  "ì§€ìˆ˜ì´ë™í‰ê· ", "ê±°ë˜ëŸ‰" ë“± ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
---
### 2. ğŸ“° [Insight] ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„

**ë‰´ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡**
  - news_sentiment_analyzer ë„êµ¬ ê²°ê³¼ì˜ **prediction.direction**(ìƒìŠ¹/í•˜ë½/ìœ ì§€)ì„ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.
  - ì˜ˆì¸¡ ë°©í–¥: [prediction.direction]
  - ì˜ˆ: "ì˜ˆì¸¡ ë°©í–¥: ìƒìŠ¹" ë˜ëŠ” "ì˜ˆì¸¡ ë°©í–¥: í•˜ë½"

**A. ì£¼ìš” ë‰´ìŠ¤**
  - news_sentiment_analyzer ë„êµ¬ ê²°ê³¼ì˜ evidenceì—ì„œ **ê¸ì •ì ì¸ ë‰´ìŠ¤ ë¬¶ìŒ**ê³¼ **ë¶€ì •ì ì¸ ë‰´ìŠ¤ ë¬¶ìŒ**ì„ êµ¬ë¶„í•´ì„œ í‘œì‹œí•˜ì„¸ìš”.
  - **ì¤‘ìš”**: titleê³¼ all_textê°€ ì˜ì–´ë¡œ ë˜ì–´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”.
  - **ì‹¬ë¦¬ íŒë‹¨**: price_impact_score > 0 ì´ë©´ ê¸ì •, < 0 ì´ë©´ ë¶€ì •, = 0 ì´ë©´ ì¤‘ë¦½
  
  **A-1. ê¸ì •ì ì¸ ë‰´ìŠ¤**
  | No | ë‰´ìŠ¤ ì œëª© | ë‚´ìš© ìš”ì•½ |
  |:--:|-----------|-----------|
  | 1 | [ë‰´ìŠ¤ ì œëª©(í•œêµ­ì–´ ë²ˆì—­)] | [all_text ìš”ì•½(í•œêµ­ì–´)] |
  | 2 | [ë‰´ìŠ¤ ì œëª©(í•œêµ­ì–´ ë²ˆì—­)] | [all_text ìš”ì•½(í•œêµ­ì–´)] |
  | ... | ... | ... |
  
  **A-2. ë¶€ì •ì ì¸ ë‰´ìŠ¤**
  | No | ë‰´ìŠ¤ ì œëª© | ë‚´ìš© ìš”ì•½ |
  |:--:|-----------|-----------|
  | 1 | [ë‰´ìŠ¤ ì œëª©(í•œêµ­ì–´ ë²ˆì—­)] | [all_text ìš”ì•½(í•œêµ­ì–´)] |
  | 2 | [ë‰´ìŠ¤ ì œëª©(í•œêµ­ì–´ ë²ˆì—­)] | [all_text ìš”ì•½(í•œêµ­ì–´)] |
  | ... | ... | ... |


**B. ì£¼ìš” í‚¤ì›Œë“œ**: [keyword_analyzer ê²°ê³¼ì˜ top_entities ìƒìœ„ 10ê°œ entity]

**C. ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤**
  - pastnews_rag ë„êµ¬ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì•„ë˜ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.
  - **ì¤‘ìš”**: all_textê°€ ì˜ì–´ë¡œ ë˜ì–´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ "ë‰´ìŠ¤ ë‚´ìš©" ì»¬ëŸ¼ì— í‘œì‹œí•˜ì„¸ìš”.
  - "ì—°ê´€ í‚¤ì›Œë“œ" ì»¬ëŸ¼ì—ëŠ” **keyword_analyzerê°€ ë°˜í™˜í•œ top_triples ì• 5ê°œì˜ keywords**ë¥¼ #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 ë˜ëŠ” í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ **êµ¬ë¶„í•´ì„œ** í‘œì‹œí•˜ì„¸ìš” (ê° í‚¤ì›Œë“œë¥¼ ëª…í™•íˆ êµ¬ë¶„).
  
  | ë‰´ìŠ¤ ë‚ ì§œ | ë‰´ìŠ¤ ë‚´ìš© | ë‹¹ì¼ | 1ì¼í›„ | 3ì¼í›„ |
  |-----------|-----------|------|------|------|
  | [ë‰´ìŠ¤ ë‚ ì§œ] | [ë‰´ìŠ¤ ë‚´ìš©(í•œêµ­ì–´ ë²ˆì—­)] | [0] | [1] | [3] |
  | [ë‰´ìŠ¤ ë‚ ì§œ] | [ë‰´ìŠ¤ ë‚´ìš©(í•œêµ­ì–´ ë²ˆì—­)] | [0] | [1] | [3] |
  | ... | ... | ... | ... | ... |

**D. ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„**

  * **ì£¼ìš” ë‰´ìŠ¤ ë¶„ì„**
    - ì£¼ìš” ê¸ì • ìš”ì¸: [ê¸ì •ì  ë‰´ìŠ¤ë“¤ì˜ ê³µí†µ ì£¼ì œ/í‚¤ì›Œë“œ]
    - ì£¼ìš” ë¶€ì • ìš”ì¸: [ë¶€ì •ì  ë‰´ìŠ¤ë“¤ì˜ ê³µí†µ ì£¼ì œ/í‚¤ì›Œë“œ]

  * **ê³¼ê±° ìœ ì‚¬ ìƒí™© ë¶„ì„**
    - C ì„¹ì…˜ì˜ ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¹ì‹œ ì‹œì¥ ë°˜ì‘(ë‹¹ì¼, 1ì¼í›„, 3ì¼í›„ ê°€ê²© ë³€ë™)ì„ ì„œìˆ 
    - ê³µí†µ íŒ¨í„´: [ê³¼ê±° ìœ ì‚¬ ë‰´ìŠ¤ ë°œìƒ ì‹œ ê°€ê²© ë³€ë™ íŒ¨í„´]

  * **ì¢…í•© ì‹œì¥ ì‹¬ë¦¬**
    - íŒë‹¨: [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì ]
    - ê·¼ê±°: [ìœ„ì˜ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì¢…í•© íŒë‹¨ ì´ìœ ]
---

### 3. ì¢…í•© ì˜ê²¬

* **í€€íŠ¸ ë¶„ì„ ìš”ì•½** :
  - Prophet ì˜ˆì¸¡: [yhat] ([ìƒìŠ¹/í•˜ë½])
  - XGBoost ë°©í–¥: [forecast_direction] (Up/Down)
  - ì£¼ìš” ê·¼ê±°: [trend, EMA, Volume ë“± í•µì‹¬ ìš”ì¸ ìš”ì•½]

* **ë‰´ìŠ¤ ì‹¬ë¦¬ ë¶„ì„ ìš”ì•½** :
  - ì‹œì¥ ì‹¬ë¦¬: [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì ]
  - ì£¼ìš” í…Œë§ˆ: [í•µì‹¬ í‚¤ì›Œë“œ ë° í…Œë§ˆ]

* **ìµœì¢… íˆ¬ì ì˜ê²¬**:
  - **ë‹¨ê¸° ì „ë§** : [í€€íŠ¸ + ë‰´ìŠ¤ ë¶„ì„ ì¢…í•©]
  - **í•µì‹¬ ê·¼ê±°**: [í€€íŠ¸ ëª¨ë¸ê³¼ ë‰´ìŠ¤ ì‹¬ë¦¬ê°€ ì¼ì¹˜/ë¶ˆì¼ì¹˜í•˜ëŠ”ì§€, ì–´ë–¤ ì‹ í˜¸ê°€ ë” ê°•í•œì§€]
  - **íˆ¬ìì ì¡°ì–¸**: 
    * **íˆ¬ì ì˜ê²¬**: [BUY/SELL/HOLD]
    * **ì˜ê²¬ ê·¼ê±°**: [ì„¹ì…˜ 1ì˜ í€€íŠ¸ ë¶„ì„ê³¼ ì„¹ì…˜ 2ì˜ ë‰´ìŠ¤ ì‹¬ë¦¬ ë¶„ì„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ë©° ì¢…í•©. ì˜ˆ: "XGBoostê°€ Downì„ ì˜ˆì¸¡í–ˆê³ (EMA -1.25, Volume -0.50), ë‰´ìŠ¤ ì‹¬ë¦¬ë„ ë¶€ì •ì (ê°€ë­„ ìš°ë ¤ 5ê±´)ì´ë¯€ë¡œ SELL"]
    * **ì£¼ìš” ë¦¬ìŠ¤í¬**: [ì˜ˆìƒë˜ëŠ” ë¦¬ìŠ¤í¬ ìš”ì¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ. ì˜ˆ: "ë³€ë™ì„±ì´ ë†’ì•„(55) ë‹¨ê¸° ê¸‰ë“± ê°€ëŠ¥ì„± ì¡´ì¬", "ì •ë¶€ ì •ì±… ë³€í™” ì‹œ ë°˜ë“± ê°€ëŠ¥"]

**ì¤‘ìš”**: 
- ë°˜ë“œì‹œ ìœ„ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
- í‘œ í˜•ì‹ì€ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ì„¹ì…˜ ë²ˆí˜¸ì™€ ì œëª©ì€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
- ê° ì„¹ì…˜ì€ "---"ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
- ì£¼ìš” í‚¤ì›Œë“œëŠ” #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ í‘œê¸°
- ë‰´ìŠ¤ ê´€ë ¨ ë‚´ìš©ì´ ì˜ì–´ë¡œ ë˜ì–´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”. ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”.
- ì–¸ì–´ëŠ” ë°˜ë“œì‹œ ìˆœìˆ˜ í•œêµ­ì–´(í•œê¸€)ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."""

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬**:
1. timeseries_predictor: Prophet + XGBoost í•˜ì´ë¸Œë¦¬ë“œ ì‹œê³„ì—´ ì˜ˆì¸¡
   - target_date: ë¶„ì„í•  ëŒ€ìƒ ë‚ ì§œ (í˜•ì‹: "YYYY-MM-DD")
   - commodity: ìƒí’ˆëª… (corn, soybean, wheat)
   - ì„¤ëª…: íŠ¹ì • í’ˆëª©ì˜ ê°€ê²© ì˜ˆì¸¡(yhat)ê³¼ ë°©í–¥ ì˜ˆì¸¡(forecast_direction)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

2. news_sentiment_analyzer: ë‰´ìŠ¤ ê¸°ë°˜ ì‹œì¥ ì˜í–¥ë ¥ ë¶„ì„ ë° ê·¼ê±° ì¶”ì¶œ
   - target_date: ë¶„ì„í•  ëŒ€ìƒ ë‚ ì§œ (í˜•ì‹: "YYYY-MM-DD")
   - commodity: ìƒí’ˆëª… (corn, soybean, wheat)
   - lookback_days: ì¡°íšŒí•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ 7ì¼)
   - ì„¤ëª…: í•´ë‹¹ ë‚ ì§œ ì „í›„ì˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œì¥ ìƒìŠ¹/í•˜ë½ í™•ë¥ ì„ ì˜ˆì¸¡í•˜ê³ , ì£¼ìš” ê·¼ê±° ë‰´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

3. keyword_analyzer: ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
   - target_date: ë¶„ì„í•  ëŒ€ìƒ ë‚ ì§œ (í˜•ì‹: "YYYY-MM-DD")
   - commodity: ìƒí’ˆëª… (corn, soybean, wheat)
   - days: ë¶„ì„í•  ì¼ìˆ˜ (ê¸°ë³¸ 3ì¼)
   - ì„¤ëª…: ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œì™€ Triple(S-V-O) ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

4. pastnews_rag: ì „ë‹¬ë°›ì€ triplesë¡œ ìœ ì‚¬ ë‰´ìŠ¤ ë° ê³¼ê±° ê°€ê²© ì¡°íšŒ
   - triples_json: keyword_analyzer ê²°ê³¼ì˜ top_triples ë°°ì—´ì„ JSONìœ¼ë¡œ ì „ë‹¬
   - commodity: ìƒí’ˆëª… (corn, soybean, wheat)
   - top_k: ìœ ì‚¬ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ 2~5)
   - ì„¤ëª…: í˜„ì¬ì˜ ì£¼ìš” ë‰´ìŠ¤ ìƒí™©ì´ ê³¼ê±° ì–¸ì œ ë°œìƒí–ˆëŠ”ì§€ ì°¾ê³ , ë‹¹ì‹œì˜ ê°€ê²© ë³€ë™ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

**ë„êµ¬ ì‚¬ìš© ê·œì¹™**:
- ëª¨ë“  ë„êµ¬ í˜¸ì¶œ ì‹œ í˜„ì¬ ë¶„ì„ ì¤‘ì¸ `commodity`ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•˜ì„¸ìš”.
- keyword_analyzer í˜¸ì¶œ í›„, ê²°ê³¼ì˜ top_triples **ì• 5ê°œ**ë¥¼ ì¶”ì¶œí•˜ì—¬ pastnews_ragì— ì „ë‹¬í•˜ì„¸ìš”.
- ì´ì „ ë„êµ¬ê°€ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•˜ë”ë¼ë„, ë„¤ ë„êµ¬ë¥¼ ë°˜ë“œì‹œ ëª¨ë‘ í˜¸ì¶œí•œ ë’¤ì—ë§Œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- ëª¨ë“  ì˜ì–´ í…ìŠ¤íŠ¸(ë‰´ìŠ¤ ì œëª©, ë‚´ìš© ë“±)ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ë³´ê³ ì„œì— í¬í•¨í•˜ì„¸ìš”.
- **ë‰´ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡**: news_sentiment_analyzer ê²°ê³¼ì˜ **prediction.direction**(ìƒìŠ¹/í•˜ë½/ìœ ì§€)ì„ '### 2. ğŸ“° [Insight] ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„' ì„¹ì…˜ì˜ "ë‰´ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡" í•­ëª©ì— í‘œì‹œí•˜ì„¸ìš”. ì˜ˆ: "ì˜ˆì¸¡ ë°©í–¥: ìƒìŠ¹" ë˜ëŠ” "ì˜ˆì¸¡ ë°©í–¥: í•˜ë½".
- `news_sentiment_analyzer` ê²°ê³¼ì˜ evidenceì—ì„œ **ê¸ì •ì ì¸ ë‰´ìŠ¤ ë¬¶ìŒ**ê³¼ **ë¶€ì •ì ì¸ ë‰´ìŠ¤ ë¬¶ìŒ**ì„ '### 2. ğŸ“° [Insight] ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„' ì„¹ì…˜ì˜ 'ì£¼ìš” ë‰´ìŠ¤'ì—ì„œ êµ¬ë¶„í•´ì„œ í‘œì‹œí•˜ì„¸ìš”.
  - **A-1. ê¸ì •ì ì¸ ë‰´ìŠ¤**: (ë‚´ë¶€ì ìœ¼ë¡œëŠ” evidence.supporting_newsë¥¼ ì°¸ê³ í•˜ë˜, í™”ë©´ì—ëŠ” ë³€ìˆ˜ëª… ë…¸ì¶œ ê¸ˆì§€)
  - **A-2. ë¶€ì •ì ì¸ ë‰´ìŠ¤**: (ë‚´ë¶€ì ìœ¼ë¡œëŠ” evidence.opposing_newsë¥¼ ì°¸ê³ í•˜ë˜, í™”ë©´ì—ëŠ” ë³€ìˆ˜ëª… ë…¸ì¶œ ê¸ˆì§€)
  - í‘œì—ëŠ” ì œëª©(title)ê³¼ ë‚´ìš©(all_text ìš”ì•½)ë§Œ ë„£ìœ¼ì„¸ìš”. **titleê³¼ all_textëŠ” ì˜ì–´ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.**
  | No | ë‰´ìŠ¤ ì œëª© | ë‚´ìš© ìš”ì•½ |
  |:--:|-----------|-----------|
  | [ë²ˆí˜¸] | [ë‰´ìŠ¤ ì œëª©(í•œêµ­ì–´ ë²ˆì—­)] | [all_text ìš”ì•½(í•œêµ­ì–´)] |
- `pastnews_rag` ë„êµ¬ ê²°ê³¼(article_info)ëŠ” 'ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤' í‘œì— ì•„ë˜ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”. **ë‰´ìŠ¤ ë‚´ìš©**ì€ article_infoì˜ all_textë¥¼ ì‚¬ìš©í•˜ê³ , ì˜ì–´ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. **ì—°ê´€ í‚¤ì›Œë“œ** ì»¬ëŸ¼ì—ëŠ” keyword_analyzerê°€ ë°˜í™˜í•œ **top_triples ì• 5ê°œì˜ keywords**ë¥¼ #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 ë˜ëŠ” í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ë„£ìœ¼ì„¸ìš” (ì €ì¥í•´ ë‘” ê°’ ì‚¬ìš©).
  | ë‰´ìŠ¤ ë‚ ì§œ | ë‰´ìŠ¤ ë‚´ìš© | ì—°ê´€ í‚¤ì›Œë“œ | ë‹¹ì¼ | 1ì¼í›„ | 3ì¼í›„ |
  |-----------|-----------|-------------|------|------|------|
  | [ë‰´ìŠ¤ ë‚ ì§œ] | [ë‰´ìŠ¤ ë‚´ìš©(í•œêµ­ì–´)] | [#í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 ë˜ëŠ” í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2] | [0] | [1] | [3] |
- `timeseries_predictor` ê²°ê³¼ í™œìš©ë²•:
  * **ê¸°ë³¸ ì •ë³´**: y(ì–´ì œ ì¢…ê°€), yhat(Prophet ì˜ˆì¸¡ê°’), forecast_direction(XGBoost ë°©í–¥ ì˜ˆì¸¡)ì„ ì¢…í•© íˆ¬ì ì˜ê²¬ í‘œì— í‘œì‹œ
  * **ì‹œê³„ì—´ ì„±ë¶„ í•´ì„** (B-1 ì„¹ì…˜):
    - trend: ê°’ê³¼ í•¨ê»˜ ì¶”ì„¸ í•´ì„. ê¸°ì¤€ - ìƒìŠ¹ ì¶”ì„¸(> 108.88), íš¡ë³´ ì¶”ì„¸(74.58~108.88), í•˜ë½ ì¶”ì„¸(< 74.58). ì˜ˆ: "94.34 (ìƒìŠ¹ ì¶”ì„¸)" ë˜ëŠ” "80.00 (íš¡ë³´ ì¶”ì„¸)" ë˜ëŠ” "60.00 (í•˜ë½ ì¶”ì„¸)"
    - yearly: ì—°ê°„ ì£¼ê¸° ì„±ë¶„. ì˜ˆ: "+0.12 (ê¸ì •ì  ì˜í–¥)" ë˜ëŠ” "-0.08 (ë¶€ì •ì  ì˜í–¥)"
    - weekly: ì£¼ê°„ ì£¼ê¸° ì„±ë¶„. ì˜ˆ: "+0.12 (ê¸ì •ì  ì˜í–¥)" ë˜ëŠ” "-0.08 (ë¶€ì •ì  ì˜í–¥)"
    - volatility: ë³€ë™ì„± ì§€í‘œ. ê¸°ì¤€ - ë‚®ìŒ(< 40), ì¤‘ê°„(40~50), ë†’ìŒ(> 50). ì˜ˆ: "42 (ì¤‘ê°„ ìˆ˜ì¤€)" ë˜ëŠ” "55 (ë†’ìŒ ìˆ˜ì¤€)" ë˜ëŠ” "35 (ë‚®ìŒ ìˆ˜ì¤€)"
  * **ê¸°ìˆ ì  ì§€í‘œ í•´ì„** (B-2 ì„¹ì…˜, ê·¸ë ˆì¸ì € ê²€ì‚¬ë¡œ ì„ ì •ëœ Lag Features):
    - EMA (ì§€ìˆ˜ì´ë™í‰ê· ): EMA_lag2_effect ê°’ì„ ì‚¬ìš©í•˜ë˜, "ì§€ìˆ˜ì´ë™í‰ê· " ë˜ëŠ” "EMA"ë¡œ í‘œí˜„. ì˜ˆ: "ì§€ìˆ˜ì´ë™í‰ê·  +1.25 (ìƒìŠ¹ ìš”ì¸)" ë˜ëŠ” "EMA -1.25 (í•˜ë½ ìš”ì¸)"
    - Volume (ê±°ë˜ëŸ‰): Volume_lag5_effect ê°’ì„ ì‚¬ìš©í•˜ë˜, "ê±°ë˜ëŸ‰"ìœ¼ë¡œ í‘œí˜„. ì˜ˆ: "ê±°ë˜ëŸ‰ +0.85 (ìƒìŠ¹ ìš”ì¸)" ë˜ëŠ” "ê±°ë˜ëŸ‰ -0.50 (í•˜ë½ ìš”ì¸)"
  * **ì¢…í•© í•´ì„** (C ì„¹ì…˜):
    - Prophet ì˜ˆì¸¡(yhat)ê³¼ XGBoost ë°©í–¥(forecast_direction)ì˜ ì¼ì¹˜/ë¶ˆì¼ì¹˜ë¥¼ ëª…í™•íˆ ë°íˆì„¸ìš”
    - ìœ„ì˜ ì‹œê³„ì—´ ì„±ë¶„(trend, yearly, weekly, volatility)ê³¼ ê¸°ìˆ ì  ì§€í‘œ(EMA, Volume)ë¥¼ **ëª¨ë‘ ê·¼ê±°ë¡œ ì œì‹œ**í•˜ì—¬ XGBoostê°€ í•´ë‹¹ ë°©í–¥ì„ ì˜ˆì¸¡í•œ ì´ìœ ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”
    - ê¸°ìˆ ì  ë³€ìˆ˜ëª…(_lag2_effect ë“±)ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ¬ìš´ ìš©ì–´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
    - ì˜ˆ: "Prophetì€ 460.5ë¡œ ìƒìŠ¹ì„ ì˜ˆì¸¡í–ˆìœ¼ë‚˜, XGBoostëŠ” Downì„ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤. ì¶”ì„¸(85.5, íš¡ë³´ ì¶”ì„¸)ëŠ” ì¤‘ë¦½ì ì´ë‚˜, ì§€ìˆ˜ì´ë™í‰ê· (-1.25)ê³¼ ê±°ë˜ëŸ‰(-0.50)ì´ ëª¨ë‘ í•˜ë½ ìš”ì¸ìœ¼ë¡œ ì‘ìš©í–ˆìœ¼ë©°, ë³€ë™ì„±(42, ì¤‘ê°„ ìˆ˜ì¤€)ë„ ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤."
- `news_sentiment_analyzer` ê²°ê³¼ì˜ evidenceì—ì„œ ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ë¬¶ìŒì„ êµ¬ë¶„í•´ì„œ í‘œì‹œí•˜ì„¸ìš”. ê° ë‰´ìŠ¤ì˜ ì œëª©(title), ë‚´ìš©(all_text ìš”ì•½)ì„ ë³´ê³ ì„œ í‘œì— í¬í•¨í•˜ì„¸ìš”. ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ì¸ prediction.directionì€ 'ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„' ì„¹ì…˜ì˜ "ë‰´ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡" í•­ëª©ì— í‘œì‹œí•˜ì„¸ìš”.
- `pastnews_rag` ë„êµ¬ ê²°ê³¼(article_info)ëŠ” 'ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤' í‘œì— í‘œì‹œí•˜ì„¸ìš”. "ì—°ê´€ í‚¤ì›Œë“œ" ì»¬ëŸ¼ì—ëŠ” **keyword_analyzer ê²°ê³¼ì˜ top_triples ì• 5ê°œì˜ keywords**ë¥¼ #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 ë˜ëŠ” í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ë„£ìœ¼ì„¸ìš” (ì´ë¯¸ í˜¸ì¶œ ê²°ê³¼ë¡œ ì €ì¥ëœ ê°’ì„ ì‚¬ìš©).
- **D. ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„** ì„¹ì…˜ ì‘ì„± ë°©ë²•:
  * A-1(ê¸ì • ë‰´ìŠ¤)ê³¼ A-2(ë¶€ì • ë‰´ìŠ¤)ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ê¸ì • ìš”ì¸ê³¼ ë¶€ì • ìš”ì¸ì„ ë¶„ì„í•˜ì„¸ìš”
  * C ì„¹ì…˜ì˜ ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤ì—ì„œ ë‹¹ì¼, 1ì¼í›„, 3ì¼í›„ ê°€ê²© ë³€ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ì„¸ìš”
  * ìœ„ ë‘ ê°€ì§€ë¥¼ ì¢…í•©í•˜ì—¬ í˜„ì¬ ì‹œì¥ ì‹¬ë¦¬ë¥¼ [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì ] ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ê³  ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”
- `keyword_analyzer` ê²°ê³¼ì˜ top_entitiesë¥¼ í™œìš©í•  ë•Œ: (1) scoreëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. (2) entity ì´ë¦„ë§Œ ì‚¬ìš©í•˜ì—¬ ìµœëŒ€í•œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. (3) #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”. ì˜ˆ: #ì˜¥ìˆ˜ìˆ˜ #ê°€ê²© #ìˆ˜ì¶œ #ë¯¸êµ­ë†ë¬´ë¶€ #ì‹œì¥
- **### 3. ì¢…í•© ì˜ê²¬** ì„¹ì…˜ ì‘ì„± ë°©ë²•:
  * ì„¹ì…˜ 1ì˜ í€€íŠ¸ ë¶„ì„ ê²°ê³¼(Prophet, XGBoost, ì‹œê³„ì—´ ì„±ë¶„, ê¸°ìˆ ì  ì§€í‘œ)ë¥¼ ìš”ì•½í•˜ì„¸ìš”
  * ì„¹ì…˜ 2ì˜ ë‰´ìŠ¤ ì‹¬ë¦¬ ë¶„ì„ ê²°ê³¼(ì‹œì¥ ì‹¬ë¦¬ íŒë‹¨, ì£¼ìš” í…Œë§ˆ)ë¥¼ ìš”ì•½í•˜ì„¸ìš”
  * í€€íŠ¸ ëª¨ë¸ê³¼ ë‰´ìŠ¤ ì‹¬ë¦¬ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ ë¶ˆì¼ì¹˜í•˜ëŠ”ì§€ ë¶„ì„í•˜ê³ , ì–´ë–¤ ì‹ í˜¸ê°€ ë” ê°•í•œì§€ íŒë‹¨í•˜ì„¸ìš”
  * **íˆ¬ìì ì¡°ì–¸ ì‘ì„± ì‹œ íŠ¹íˆ ì£¼ì˜**: 
    - ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë§Œë“¤ì§€ ë§ê³ , ì„¹ì…˜ 1ê³¼ 2ì—ì„œ ì´ë¯¸ ë¶„ì„í•œ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ì„¸ìš”
    - BUY/SELL/HOLD ì˜ê²¬ê³¼ í•¨ê»˜ ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš” (ì˜ˆ: "XGBoost Down ì˜ˆì¸¡(EMA -1.25), ë‰´ìŠ¤ ë¶€ì •ì (ê°€ë­„ 5ê±´)")
    - ì£¼ìš” ë¦¬ìŠ¤í¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš” (ì˜ˆ: "ë³€ë™ì„± ë†’ìŒ(55), ì •ì±… ë³€í™” ì‹œ ë°˜ë“± ê°€ëŠ¥")
- ë„¤ ë„êµ¬ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë…¼ë¦¬ì ì¸ ê¸ˆìœµ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. ì‹œê³„ì—´ ì§€í‘œ(Prophet + XGBoost), ë‰´ìŠ¤ ê°ì„± ë¶„ì„, í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ê°€ ì„œë¡œ ë³´ì™„ë˜ë„ë¡ ì„œìˆ í•˜ì„¸ìš”.
- target_dateëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ ë¬¸ìì—´ ë¦¬í„°ëŸ´ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”. (YYYY-MM-DD)
- **íˆ¬ìì ì¡°ì–¸ì´ ë³´ê³ ì„œì˜ í•µì‹¬ì…ë‹ˆë‹¤**: ì„¹ì…˜ 1ê³¼ 2ì˜ ë¶„ì„ ë‚´ìš©ì„ ì¶©ì‹¤íˆ ì¸ìš©í•˜ë©°, íˆ¬ììê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì‘ì„±í•˜ì„¸ìš”. ë§‰ì—°í•œ í‘œí˜„ ëŒ€ì‹  êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ ìˆ˜ì¹˜ë¥¼ ì œì‹œí•˜ì„¸ìš”.
**ë³´ê³ ì„œ ì‘ì„± í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤)**:

"""

# LangChain Tools ì •ì˜
@tool
def timeseries_predictor(target_date: str, commodity: str = "corn") -> str:
    """
    íŠ¹ì • ë‚ ì§œì˜ íŠ¹ì • í’ˆëª©(corn, soybean, wheat)ì— ëŒ€í•œ ê¸ˆìœµ ì‹œì¥ ì¶”ì„¸(ìƒìŠ¹/í•˜ë½)ì™€ ê°€ê²©ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

    Args:
        target_date: ë¶„ì„í•  ë‚ ì§œ ë¬¸ìì—´ (í˜•ì‹: "YYYY-MM-DD")

    Returns:
        JSON í˜•ì‹ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¬¸ìì—´ (ì˜ˆì¸¡ê°’, ë°©í–¥, ì¶”ì„¸ ë¶„ì„ ë“± í¬í•¨)
    """
    return predict_market_trend(target_date, commodity=commodity)


@tool
def news_sentiment_analyzer(target_date: str, commodity: str = "corn", lookback_days: int = 7) -> str:
    """
    íŠ¹ì • ë‚ ì§œì˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ íŠ¹ì • í’ˆëª©(corn, soybean, wheat)ì˜ ì‹œì¥ ì˜í–¥ë ¥ì„ ì˜ˆì¸¡í•˜ê³  ì£¼ìš” ê·¼ê±° ë‰´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    analyzer = SentimentAnalyzer()
    
    # ì‹¤ì œ êµ¬í˜„ëœ run_daily_prediction íŒŒë¼ë¯¸í„°ì— ë§ì¶° í˜¸ì¶œ
    result = analyzer.run_daily_prediction(
        target_date=target_date,
        commodity=commodity,
        lookback_days=lookback_days,
        save_file=False,
    )
        
    return json.dumps(result, ensure_ascii=False)


@tool
def keyword_analyzer(target_date: str, commodity: str = "corn", days: int = 3) -> str:
    """
    íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. (í’ˆëª©ë³„ í•„í„°ë§ ì§€ì›)
    """
    print(f"[keyword_analyzer] ì‹¤í–‰ ì‹œì‘ (commodity: {commodity})", flush=True)
    result = json.loads(_analyze_keywords(target_date=target_date, commodity=commodity, days=days, top_k=10))
    top_entities = result.get("top_entities", [])[:10]
    top_triples = result.get("top_triples", [])
    print("[keyword_analyzer] ì¢…ë£Œ", flush=True)
    return json.dumps({"top_entities": top_entities, "top_triples": top_triples}, ensure_ascii=False, indent=2)


@tool
def pastnews_rag(triples_json: str, commodity: str = "corn", top_k: int = 5) -> str:
    """
    ì „ë‹¬ë°›ì€ triplesë¡œ íŠ¹ì • í’ˆëª©(corn, soybean, wheat)ì˜ ìœ ì‚¬ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ê³¼ê±° ê°€ê²© ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    print(f"[pastnews_rag] ì‹¤í–‰ ì‹œì‘ (commodity: {commodity})", flush=True)
    triples = []
    if triples_json and triples_json.strip():
        try:
            parsed = json.loads(triples_json)
            if isinstance(parsed, list):
                for item in parsed:
                    if isinstance(item, (list, tuple)) and len(item) >= 3:
                        triples.append(list(item[:3]))
                    elif isinstance(item, dict) and "triple" in item and isinstance(item["triple"], (list, tuple)) and len(item["triple"]) >= 3:
                        triples.append(list(item["triple"][:3]))
        except (json.JSONDecodeError, TypeError):
            pass
    
    # ì• 5ê°œë§Œ ì‚¬ìš© (ë¦¬ì†ŒìŠ¤ ì œí•œ)
    triples = triples[:5] if triples else []
    result = _run_pastnews_rag(triples=triples if triples else None, commodity=commodity, top_k=top_k)
    print("[pastnews_rag] ì¢…ë£Œ", flush=True)
    return json.dumps(result, ensure_ascii=False, indent=2)


class LLMSummarizer:
    """Vertex AIë¥¼ ì‚¬ìš©í•˜ëŠ” LangChain Agentë¥¼ ì´ìš©í•œ í†µí•© ë¶„ì„"""

    def __init__(self, model_name: str = None, project_id: str = None, location: str = None):
        self.model_name = model_name or GENERATE_MODEL_NAME
        self.project_id = project_id or VERTEX_AI_PROJECT_ID or self._get_project_id()
        self.location = location or VERTEX_AI_LOCATION
        self.llm = None
        self.agent = None
        self._initialize()

    def _get_project_id(self) -> str:
        try:
            result = subprocess.run(
                ["gcloud", "config", "get-value", "project"], capture_output=True, text=True, timeout=2
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
            else:
                return VERTEX_AI_PROJECT_ID or "unknown"
        except Exception:
            return VERTEX_AI_PROJECT_ID or "unknown"

    def _create_llm(self) -> ChatVertexAI:
        return ChatVertexAI(
            model=self.model_name,
            project=self.project_id,
            location=self.location,
            temperature=GENERATE_MODEL_TEMPERATURE,
            max_output_tokens=GENERATE_MODEL_MAX_TOKENS,
        )

    def _initialize(self):
        self.llm = self._create_llm()
        tools = [timeseries_predictor, news_sentiment_analyzer, keyword_analyzer, pastnews_rag]
        llm_with_tools = self.llm.bind_tools(tools)
        self.agent = create_agent(model=llm_with_tools, tools=tools, system_prompt=SYSTEM_PROMPT)

    def _build_user_input(self, context: str, target_date: str, commodity: str) -> str:
        user_input = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ê¸ˆìœµ ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ëŒ€ìƒ í’ˆëª©**: {commodity}
**ë¶„ì„ ë§¥ë½**: {context or f"ìµœê·¼ {commodity} ì‹œì¥ ìƒí™© ë¶„ì„"}
**ë¶„ì„ ê¸°ì¤€ ì¼ì**: {target_date}

- ëª¨ë“  ë„êµ¬ í˜¸ì¶œ ì‹œ `commodity='{commodity}'` ì¸ìë¥¼ ë°˜ë“œì‹œ ì „ë‹¬í•˜ì„¸ìš”.
- ë‹¤ìŒ ìˆœì„œë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”:
  1. `timeseries_predictor(target_date="{target_date}", commodity='{commodity}')`
  2. `news_sentiment_analyzer(target_date="{target_date}", commodity='{commodity}')`
  3. `keyword_analyzer(target_date="{target_date}", commodity='{commodity}')`
  4. keyword_analyzer ê²°ê³¼ì˜ **top_triples ì• 5ê°œ**ì—ì„œ "triple"ë§Œ ì¶”ì¶œí•´ `pastnews_rag(triples_json="...", top_k=2)` í˜¸ì¶œ. ì—°ê´€ í‚¤ì›Œë“œëŠ” ê·¸ ì• 5ê°œ top_triplesì˜ keywordsë¥¼ ì €ì¥í•´ ë‘ì—ˆë‹¤ê°€ ë³´ê³ ì„œ í‘œì— ì‚¬ìš©í•˜ì„¸ìš”.
- **pastnews_rag í˜¸ì¶œ ì˜ˆì‹œ**: keyword_analyzerê°€ {{"top_triples": [{{"triple": ["A","B","C"], "keywords": ["x","y"]}}, ...]}}ë¥¼ ë°˜í™˜í•˜ë©´, **ì• 5ê°œë§Œ** ì‚¬ìš©í•´ `pastnews_rag(triples_json='[["A","B","C"], ...]', top_k=2)` í˜¸ì¶œ (ìµœëŒ€ 5ê°œ). í‘œì˜ "ì—°ê´€ í‚¤ì›Œë“œ"ì—ëŠ” ê·¸ ì• 5ê°œ top_triplesì˜ keywordsë¥¼ #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 ë˜ëŠ” í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ í‘œì‹œ.
- `timeseries_predictor` ê²°ê³¼ í™œìš©:
  * y, yhat, forecast_directionì„ ì¢…í•© íˆ¬ì ì˜ê²¬ í‘œì— í‘œì‹œ
  * **B-1. ì‹œê³„ì—´ ì„±ë¶„**: 
    - trend: ìƒìŠ¹ ì¶”ì„¸(> 108.88), íš¡ë³´ ì¶”ì„¸(74.58~108.88), í•˜ë½ ì¶”ì„¸(< 74.58) ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨. ì˜ˆ: "94.34 (ìƒìŠ¹ ì¶”ì„¸)" ë˜ëŠ” "80.00 (íš¡ë³´ ì¶”ì„¸)"
    - yearly, weekly: "+0.12 (ê¸ì •ì  ì˜í–¥)" ë˜ëŠ” "-0.08 (ë¶€ì •ì  ì˜í–¥)" í˜•íƒœë¡œ í‘œí˜„
    - volatility: ê°’ê³¼ í•¨ê»˜ ë‚®ìŒ(< 40), ì¤‘ê°„(40~50), ë†’ìŒ(> 50) ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨. ì˜ˆ: "42 (ì¤‘ê°„ ìˆ˜ì¤€)"
  * **B-2. ê¸°ìˆ ì  ì§€í‘œ**: ë³€ìˆ˜ëª… ëŒ€ì‹  ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©. "ì§€ìˆ˜ì´ë™í‰ê·  +1.25 (ìƒìŠ¹ ìš”ì¸)" ë˜ëŠ” "ê±°ë˜ëŸ‰ -0.50 (í•˜ë½ ìš”ì¸)" í˜•íƒœë¡œ í‘œí˜„. ì ˆëŒ€ _lag2_effect ê°™ì€ ë³€ìˆ˜ëª… ì‚¬ìš© ê¸ˆì§€
  * **C. ì¢…í•© í•´ì„**: ìœ„ì˜ ëª¨ë“  ìš”ì¸(ì‹œê³„ì—´ ì„±ë¶„ + ê¸°ìˆ ì  ì§€í‘œ)ì„ ê·¼ê±°ë¡œ Prophetê³¼ XGBoost ì˜ˆì¸¡ì„ ë¹„êµ ë¶„ì„. ê¸°ìˆ ì  ë³€ìˆ˜ëª… ì‚¬ìš© ê¸ˆì§€
- `news_sentiment_analyzer` ë° `pastnews_rag` ê²°ê³¼ í™œìš©:
  * **D. ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„**: 
    - A-1(ê¸ì • ë‰´ìŠ¤)ê³¼ A-2(ë¶€ì • ë‰´ìŠ¤)ì—ì„œ ì£¼ìš” ê¸ì • ìš”ì¸ê³¼ ë¶€ì • ìš”ì¸ ë¶„ì„
    - ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤ì˜ ë‹¹ì¼/1ì¼í›„/3ì¼í›„ ê°€ê²© ë³€ë™ íŒ¨í„´ ë¶„ì„
    - ìœ„ ë‘ ê°€ì§€ë¥¼ ì¢…í•©í•˜ì—¬ ì‹œì¥ ì‹¬ë¦¬ë¥¼ [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì ] ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•˜ê³  ê·¼ê±° ì œì‹œ
- `keyword_analyzer`ì˜ ê²°ê³¼(top_entities)ë¥¼ í™œìš©í•˜ì—¬ B ì„¹ì…˜ì— ì£¼ìš” í‚¤ì›Œë“œë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ í›„ #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”. scoreëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- **### 3. ì¢…í•© ì˜ê²¬ - íˆ¬ìì ì¡°ì–¸ ì‘ì„± ì‹œ íŠ¹ë³„ ì§€ì¹¨**:
  * íˆ¬ìì ì¡°ì–¸ì´ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‚¬í•­ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:
  * **ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”**: ì„¹ì…˜ 1(í€€íŠ¸)ê³¼ ì„¹ì…˜ 2(ë‰´ìŠ¤)ì—ì„œ ì´ë¯¸ ë¶„ì„í•œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
  * **êµ¬ì²´ì ì¸ ê·¼ê±° ì œì‹œ**: BUY/SELL/HOLD ì˜ê²¬ì„ ë‚¼ ë•Œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ì¸ìš©í•˜ì„¸ìš”. ë‹¨, ë³€ìˆ˜ëª…ì€ ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
    - ì˜ˆ: "XGBoostê°€ Down ì˜ˆì¸¡(ì§€ìˆ˜ì´ë™í‰ê·  -1.25, ê±°ë˜ëŸ‰ -0.50)í•˜ê³ , ë‰´ìŠ¤ ì‹¬ë¦¬ë„ ë¶€ì •ì (ê°€ë­„ ìš°ë ¤ ë‰´ìŠ¤ 5ê±´)"
  * **ë¦¬ìŠ¤í¬ êµ¬ì²´í™”**: ë‹¨ìˆœíˆ "ë¦¬ìŠ¤í¬ ì¡´ì¬"ê°€ ì•„ë‹ˆë¼ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¦¬ìŠ¤í¬ì¸ì§€ ëª…ì‹œí•˜ì„¸ìš”
    - ì˜ˆ: "ë³€ë™ì„±ì´ ë†’ì•„(55) ë‹¨ê¸° ê¸‰ë“± ê°€ëŠ¥ì„±", "ì •ë¶€ ì •ì±… ë³€í™” ì‹œ ë°˜ë“± ê°€ëŠ¥"
"""
        return user_input

    def summarize(self, context: str = "", target_date: Optional[str] = None, commodity: str = "corn", max_retries: int = 2) -> dict:
        if not target_date:
            target_date = datetime.now().strftime("%Y-%m-%d")

        user_input = self._build_user_input(context=context, target_date=target_date, commodity=commodity)

        for attempt in range(max_retries + 1):
            try:
                result = self.agent.invoke({"messages": [HumanMessage(content=user_input)]})
                summary = self._extract_summary_from_result(result)
                
                if summary and len(summary.strip()) > 50:
                    return {"summary": summary, "agent_result": result}
            except Exception as e:
                print(f"âš ï¸ Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {attempt+1}): {e}")
                if attempt == max_retries: raise e

        return {"summary": "", "agent_result": {}}
        
    def _validate_output_format(self, summary: str) -> bool:
        """ì¶œë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦ (ìµœì†Œ ê²€ì¦)

        Returns:
            bool: í˜•ì‹ì´ ì˜¬ë°”ë¥´ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False
        """
        # ìµœì†Œí•œì˜ ê¸¸ì´ í™•ì¸
        if not summary or len(summary.strip()) < 100:
            return False

        return True

    def _normalize_ai_content(self, content) -> str:
        """Vertex AI ë“±ì—ì„œ contentê°€ [{'type': 'text', 'text': '...'}, ...] í˜•íƒœì¼ ë•Œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
        if content is None:
            return ""
        # ë¦¬ìŠ¤íŠ¸(part í˜•ì‹)ì¸ ê²½ìš°
        if isinstance(content, list):
            parts = []
            for part in content:
                if isinstance(part, dict) and part.get("type") == "text" and "text" in part:
                    parts.append(str(part["text"]))
            if parts:
                return "\n".join(parts)
        # ë¬¸ìì—´ë¡œ ì§ë ¬í™”ëœ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì˜ˆ: "[{'type': 'text', 'text': '...'}]")
        if isinstance(content, str) and content.strip().startswith("[") and "'text'" in content:
            try:
                import ast
                parsed = ast.literal_eval(content)
                if isinstance(parsed, list):
                    parts = []
                    for part in parsed:
                        if isinstance(part, dict) and part.get("type") == "text" and "text" in part:
                            parts.append(str(part["text"]))
                    if parts:
                        return "\n".join(parts)
            except (ValueError, SyntaxError):
                pass
        return str(content)

    def _extract_summary_from_result(self, result: dict) -> str:
        """Agent ì‹¤í–‰ ê²°ê³¼ì—ì„œ ìš”ì•½ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        import json

        messages = result.get("messages", [])

        # messagesì—ì„œ ë§ˆì§€ë§‰ AIMessageì˜ content ì¶”ì¶œ
        for msg in reversed(messages):
            if isinstance(msg, AIMessage):
                raw = msg.content
                content = self._normalize_ai_content(raw)
                content = content.strip().rstrip("\\")

                # JSON í˜•ì‹ì˜ tool call argumentsëŠ” ê±´ë„ˆë›°ê¸°
                if content.startswith("{{") and content.strip().endswith("}}"):
                    try:
                        # JSON íŒŒì‹± ì‹œë„
                        parsed = json.loads(content)
                        # tool call arguments í˜•ì‹ì¸ì§€ í™•ì¸ (texts, data ë“±ì˜ í‚¤ê°€ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°)
                        if isinstance(parsed, dict) and any(key in parsed for key in ["texts", "data", "target_date"]):
                            continue
                    except (json.JSONDecodeError, ValueError):
                        # JSONì´ ì•„ë‹ˆë©´ ê³„ì† ì§„í–‰
                        pass

                # GPT-OSS-20B íŠ¹ìˆ˜ í˜•ì‹ ì œê±° (<|channel|> ë“±)
                # tool calling í˜•ì‹ì¸ ê²½ìš° ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                if content.startswith("<|channel|>") and "<|call|>" in content:
                    # tool calling í˜•ì‹ì´ê³  ì‹¤ì œ ë³´ê³ ì„œ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                    if not any(keyword in content for keyword in ["ë³´ê³ ì„œ", "ë¶„ì„", "ì˜ê²¬", "ì „ë§", "ì‹œì¥"]):
                        continue

                if content and len(content) > 50:  # ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ
                    return content

        # messagesì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° output í•„ë“œ í™•ì¸
        output = result.get("output") or result.get("final_output")
        if output:
            return str(output).strip().rstrip("\\")

        # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ ì „ì²´ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        return str(result).strip().rstrip("\\")

    # TODO ì¬ì‹œë„ ë¡œì§ ì ê²€
    def summarize(
        self,
        context: str = "",
        target_date: Optional[str] = None,
        max_retries: int = 2,
    ) -> dict:
        """LangChain Agentë¥¼ ì´ìš©í•œ LLM ìš”ì•½ ìƒì„±

        Args:
            context: ë¶„ì„ ë§¥ë½
            target_date: ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ (YYYY-MM-DD)
            max_retries: ì¬ì‹œë„ íšŸìˆ˜
        """
        # ë‚ ì§œ ê¸°ë³¸ê°’ (ì˜¤ëŠ˜)
        if not target_date:
            from datetime import datetime

            target_date = datetime.now().strftime("%Y-%m-%d")

        user_input = self._build_user_input(context=context, target_date=target_date)

        for attempt in range(max_retries + 1):
            # Agent ì‹¤í–‰ (LangChainì´ ìë™ìœ¼ë¡œ tool callì„ ì²˜ë¦¬í•¨)
            if attempt == 0:
                result = self.agent.invoke({"messages": [HumanMessage(content=user_input)]})
            else:
                # ì¬ì‹œë„ ì‹œ ê¸°ì¡´ ë©”ì‹œì§€ ì‚¬ìš©
                result = self.agent.invoke({"messages": result.get("messages", [])})

            # ê²°ê³¼ ì¶”ì¶œ
            if isinstance(result, dict):
                messages = result.get("messages", [])

                summary = self._extract_summary_from_result(result)
                agent_result = result
                # ë””ë²„ê¹…: ë©”ì‹œì§€ ìƒíƒœ í™•ì¸
                print(f"\n[ë””ë²„ê¹…] ì´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
                tool_call_count = sum(1 for msg in messages if isinstance(msg, AIMessage) and msg.tool_calls)
                tool_result_count = sum(1 for msg in messages if hasattr(msg, "name") and msg.name)
                print(f"  Tool í˜¸ì¶œ: {tool_call_count}íšŒ, Tool ê²°ê³¼: {tool_result_count}ê°œ")
            else:
                summary = str(result).strip().rstrip("\\")
                agent_result = {"messages": []}

            # ìš”ì•½ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš° í™•ì¸
            if not summary or len(summary.strip()) < 50:
                print(f"\nâš ï¸ ìš”ì•½ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ê¸¸ì´: {len(summary)}ì)")
                # ë§ˆì§€ë§‰ AIMessageì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì°¾ê¸° (Vertex AI part í˜•ì‹ í¬í•¨)
                if isinstance(result, dict):
                    messages = result.get("messages", [])
                    for msg in reversed(messages):
                        if isinstance(msg, AIMessage) and msg.content:
                            content = self._normalize_ai_content(msg.content)
                            if "<|channel|>" not in content and len(content.strip()) > 50:
                                summary = content.strip()
                                print(f"  â†’ ëŒ€ì²´ í…ìŠ¤íŠ¸ ë°œê²¬ (ê¸¸ì´: {len(summary)}ì)")
                                break

            # ì¶œë ¥ í˜•ì‹ ê²€ì¦
            if summary and len(summary.strip()) > 50 and self._validate_output_format(summary):
                return {
                    "summary": summary or "",
                    "agent_result": agent_result,
                }

            # í˜•ì‹ì´ ë§ì§€ ì•Šìœ¼ë©´ ì¬ì‹œë„
            if attempt < max_retries:
                print(f"\nâš ï¸ ì¶œë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                print(f"í˜„ì¬ ìš”ì•½ ê¸¸ì´: {len(summary)}ì")
                if summary:
                    print(f"ìš”ì•½ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):\n{summary[:500]}...\n")

                user_input = f"""{user_input}

**ì¤‘ìš”**: ì´ì „ ì‘ë‹µì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”:

{REPORT_FORMAT}

**íŠ¹íˆ ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”**:
1. ì„¹ì…˜ ì œëª©ì´ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤: "### 1. ğŸ“ˆ [Quant] í€€íŠ¸ ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„", "### 2. ğŸ“° [Insight] ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„", "### 3. ì¢…í•© ì˜ê²¬"
2. ê° ì„¹ì…˜ì€ "---"ë¡œ êµ¬ë¶„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
3. ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹(|)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
4. timeseries_predictor ê²°ê³¼ì˜ y, yhat, forecast_directionì„ í‘œì— ì •í™•íˆ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤
5. **B-1. ì‹œê³„ì—´ ì„±ë¶„**ê³¼ **B-2. ê¸°ìˆ ì  ì§€í‘œ**ë¥¼ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤. trendëŠ” ìƒìŠ¹(> 108.88), íš¡ë³´(74.58~108.88), í•˜ë½(< 74.58) ê¸°ì¤€, ë³€ë™ì„±ì€ ë‚®ìŒ(< 40), ì¤‘ê°„(40~50), ë†’ìŒ(> 50) ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”
6. **C. í€€íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ í•´ì„**ì—ì„œ ëª¨ë“  ìš”ì¸(ì¶”ì„¸, ì—°ê°„ì£¼ê¸°, ì£¼ê°„ì£¼ê¸°, ë³€ë™ì„±, ì§€ìˆ˜ì´ë™í‰ê· , ê±°ë˜ëŸ‰)ì„ ê·¼ê±°ë¡œ Prophetê³¼ XGBoost ì˜ˆì¸¡ì„ ë¹„êµ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤. ë³€ìˆ˜ëª…(_lag2_effect ë“±)ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
7. **D. ë‰´ìŠ¤ ë¹…ë°ì´í„° ê¸°ë°˜ ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„**ì—ì„œ A-1(ê¸ì • ë‰´ìŠ¤)ê³¼ A-2(ë¶€ì • ë‰´ìŠ¤)ì˜ ì£¼ìš” ê¸ì •/ë¶€ì • ìš”ì¸ê³¼ ê³¼ê±° ê´€ë ¨ ë‰´ìŠ¤ì˜ ê°€ê²© ë³€ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¢…í•© ì‹œì¥ ì‹¬ë¦¬ë¥¼ [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì ] ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤
8. 4ê°œì˜ Toolì„ ëª¨ë‘ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤: timeseries_predictor, news_sentiment_analyzer, keyword_analyzer, pastnews_rag (keyword_analyzer ê²°ê³¼ì˜ top_triplesë¥¼ JSON ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ pastnews_ragì— ì „ë‹¬)
9. Tool í˜¸ì¶œ í›„ ë°˜ë“œì‹œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤
10. **íˆ¬ìì ì¡°ì–¸ ì‘ì„± ì‹œ íŠ¹ë³„íˆ ì£¼ì˜**: 
    - ì„¹ì…˜ 1ê³¼ 2ì—ì„œ ì´ë¯¸ ë¶„ì„í•œ ë‚´ìš©ë§Œ ì‚¬ìš© (ìƒˆë¡œìš´ ì •ë³´ ë§Œë“¤ì§€ ë§ ê²ƒ)
    - BUY/SELL/HOLD ì˜ê²¬ê³¼ í•¨ê»˜ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì¸ìš©í•˜ë˜, ë³€ìˆ˜ëª… ì‚¬ìš© ê¸ˆì§€ (ì˜ˆ: "ì§€ìˆ˜ì´ë™í‰ê·  -1.25, ê±°ë˜ëŸ‰ -0.50")
    - ë¦¬ìŠ¤í¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ (ì˜ˆ: "ë³€ë™ì„± 55ë¡œ ë†’ìŒ, ì •ì±… ë³€í™” ì‹œ ë°˜ë“± ê°€ëŠ¥")"""
            else:
                print("\nâš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜•ì‹ì´ ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                print(f"ìµœì¢… ìš”ì•½ ê¸¸ì´: {len(summary)}ì")
                if summary:
                    print(f"ìš”ì•½ ë¯¸ë¦¬ë³´ê¸°: {summary[:200]}...")
                print("ê²€ì¦ì„ í†µê³¼í•˜ì§€ ëª»í–ˆì§€ë§Œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")

        return {
            "summary": summary or "",
            "agent_result": agent_result,
        }