import json
import logging
from app.schema.models import (
    OrchestratorOutput,
    TimeSeriesPrediction,
    SentimentAnalysis,
)
from app.models.llm_summarizer import LLMSummarizer
from datetime import datetime
from typing import Optional, Tuple, Union, Dict, Any

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ëª¨ë¸ ì´ˆê¸°í™” (Lazy initialization)
llm_summarizer = None


def get_llm_summarizer():
    """LLM Summarizer ì§€ì—° ì´ˆê¸°í™”"""
    global llm_summarizer
    if llm_summarizer is None:
        logger.info("LLM Summarizer ì´ˆê¸°í™” ì‹œì‘ (ì§€ì—° ì´ˆê¸°í™”)")
        llm_summarizer = LLMSummarizer()
        logger.info("LLM Summarizer ì´ˆê¸°í™” ì™„ë£Œ")
    else:
        logger.debug("ê¸°ì¡´ LLM Summarizer ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©")
    return llm_summarizer


def parse_agent_result_raw(agent_result: dict) -> Dict[str, Any]:
    """
    Agent ì‹¤í–‰ ê²°ê³¼ì—ì„œ DB ì ì¬ë¥¼ ìœ„í•œ Raw ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    Airflow íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    from langchain_core.messages import ToolMessage

    messages = agent_result.get("messages", []) if isinstance(agent_result, dict) else []
    
    extracted_data = {
        "timeseries_data": None,
        "news_data": None
    }

    for msg in messages:
        if isinstance(msg, ToolMessage):
            # ì‹œê³„ì—´ ì˜ˆì¸¡ ê²°ê³¼ (JSON)
            if msg.name == "timeseries_predictor":
                try:
                    ts_data = json.loads(msg.content)
                    if "error" not in ts_data:
                        extracted_data["timeseries_data"] = ts_data
                except json.JSONDecodeError:
                    print(f"Warning: Failed to parse timeseries JSON in raw extractor")

            # ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ (JSON)
            elif msg.name == "news_sentiment_analyzer":
                try:
                    news_res = json.loads(msg.content)
                    if "error" not in news_res:
                        extracted_data["news_data"] = news_res
                except json.JSONDecodeError:
                    print(f"Warning: Failed to parse news analysis JSON in raw extractor")

    return extracted_data


def run_market_analysis(target_date: Optional[str] = None, context: str = "ê¸ˆìœµ ì‹œì¥ ë¶„ì„") -> Dict[str, Any]:
    """
    [Airflowìš©] ì‹œì¥ ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ì ì¬í•  ëª¨ë“  ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        dict: {
            "target_date": str,
            "timeseries_data": dict, # BQ ì ì¬ìš©
            "news_data": dict,       # BQ ì ì¬ìš©
            "final_report": str      # GCS ì ì¬ìš©
        }
    """
    summarizer = get_llm_summarizer()

    # ë¶„ì„ ê¸°ì¤€ì¼ì´ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
    if not target_date:
        target_date = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸš€ Analyzing market for date: {target_date}")
    result = summarizer.summarize(context=context, target_date=target_date)
    
    # 1. Agent Tool ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
    agent_result = result.get("agent_result", {})
    raw_data = parse_agent_result_raw(agent_result)
    
    # 2. ìµœì¢… ê²°ê³¼ ì¡°í•©
    output = {
        "target_date": target_date,
        "timeseries_data": raw_data.get("timeseries_data"),
        "news_data": raw_data.get("news_data"),
        "final_report": result.get("summary", "")
    }
    
    return output


def parse_agent_result(agent_result: dict) -> Tuple[TimeSeriesPrediction, list]:
    """
    Agent ì‹¤í–‰ ê²°ê³¼ì—ì„œ Tool ë©”ì‹œì§€ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„° ë°˜í™˜
    """
    from langchain_core.messages import ToolMessage

    logger.info("=" * 80)
    logger.info("parse_agent_result ì‹œì‘")
    logger.debug(f"Agent result íƒ€ì…: {type(agent_result)}")

    messages = (
        agent_result.get("messages", []) if isinstance(agent_result, dict) else []
    )

    logger.info(f"íŒŒì‹±í•  ë©”ì‹œì§€ ì´ ê°œìˆ˜: {len(messages)}")
    logger.debug(f"ë©”ì‹œì§€ íƒ€ì… ëª©ë¡: {[type(msg).__name__ for msg in messages]}")

    timeseries_prediction = None
    sentiment_analysis = []

    tool_message_count = 0
    for idx, msg in enumerate(messages):
        if isinstance(msg, ToolMessage):
            tool_message_count += 1
            logger.info(
                f"ToolMessage ì²˜ë¦¬ ì¤‘ #{tool_message_count} (ì¸ë±ìŠ¤ {idx}): {msg.name}"
            )
            logger.debug(f"ë„êµ¬ ì½˜í…ì¸  ê¸¸ì´: {len(msg.content)} ë¬¸ì")
            logger.debug(f"ë„êµ¬ ì½˜í…ì¸  ë¯¸ë¦¬ë³´ê¸°: {msg.content[:200]}...")

            # ì‹œê³„ì—´ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì‹± (JSON)
            if msg.name == "timeseries_predictor":
                logger.info("ì‹œê³„ì—´ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì‹± ì¤‘")
                try:
                    ts_data = json.loads(msg.content)
                    logger.debug(f"íŒŒì‹±ëœ ì‹œê³„ì—´ ë°ì´í„° í‚¤: {list(ts_data.keys())}")

                    if "error" not in ts_data:
                        forecast_value = ts_data.get("forecast_value", 0.0)
                        confidence_score = ts_data.get("confidence_score", 0.0)
                        target_date = ts_data.get(
                            "target_date", datetime.now().isoformat()
                        )

                        logger.info(
                            f"ì‹œê³„ì—´ ì˜ˆì¸¡ ì¶”ì¶œ ì™„ë£Œ: ì˜ˆì¸¡ê°’={forecast_value:.2f}, ì‹ ë¢°ë„={confidence_score:.2f}%, ë‚ ì§œ={target_date}"
                        )

                        timeseries_prediction = TimeSeriesPrediction(
                            prediction=forecast_value,
                            confidence=confidence_score / 100,
                            timestamp=target_date,
                        )
                        logger.info("TimeSeriesPrediction ê°ì²´ ìƒì„± ì™„ë£Œ")
                    else:
                        error_msg = ts_data.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        logger.error(f"ì‹œê³„ì—´ ë°ì´í„°ì— ì˜¤ë¥˜ í¬í•¨: {error_msg}")

                except json.JSONDecodeError as e:
                    logger.error(f"ì‹œê³„ì—´ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    logger.error(f"ìœ íš¨í•˜ì§€ ì•Šì€ JSON ì½˜í…ì¸ : {msg.content[:200]}...")
                except Exception as e:
                    logger.error(
                        f"ì‹œê³„ì—´ ë°ì´í„° íŒŒì‹± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True
                    )

            # ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ íŒŒì‹± (JSON)
            elif msg.name == "news_sentiment_analyzer":
                logger.info("ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì¤‘")
                try:
                    news_res = json.loads(msg.content)
                    logger.debug(f"íŒŒì‹±ëœ ë‰´ìŠ¤ ê²°ê³¼ í‚¤: {list(news_res.keys())}")

                    if "error" not in news_res:
                        evidence_news = news_res.get("evidence_news", [])
                        logger.info(f"ê·¼ê±° ë‰´ìŠ¤ {len(evidence_news)}ê°œ ë°œê²¬")

                        # ê·¼ê±° ë‰´ìŠ¤ë“¤ì„ SentimentAnalysis í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
                        for news_idx, news in enumerate(evidence_news):
                            impact = news.get("price_impact_score", 0.0)
                            title = news.get("title", "ì œëª©ì—†ìŒ")
                            all_text = news.get("all_text", "")

                            logger.debug(
                                f"ë‰´ìŠ¤ #{news_idx + 1}: ì œëª©='{title[:50]}...', ì˜í–¥ë„={impact:.4f}"
                            )

                            # ì ìˆ˜ ì •ê·œí™” ë° í• ë‹¹
                            scores = {
                                "positive": max(0.0, impact) if impact > 0 else 0.1,
                                "negative": abs(impact) if impact < 0 else 0.1,
                                "neutral": 0.5,
                            }

                            sentiment_label = (
                                "positive"
                                if impact > 0
                                else ("negative" if impact < 0 else "neutral")
                            )
                            logger.debug(
                                f"ë‰´ìŠ¤ #{news_idx + 1} ê°ì„±: {sentiment_label}, ì ìˆ˜={scores}"
                            )

                            sentiment_analysis.append(
                                SentimentAnalysis(
                                    text=f"[{title}] {all_text[:200]}...",
                                    sentiment=sentiment_label,
                                    scores=scores,
                                )
                            )

                        logger.info(
                            f"SentimentAnalysis ê°ì²´ {len(sentiment_analysis)}ê°œ ìƒì„± ì™„ë£Œ"
                        )
                    else:
                        error_msg = news_res.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        logger.error(f"ë‰´ìŠ¤ ë¶„ì„ ë°ì´í„°ì— ì˜¤ë¥˜ í¬í•¨: {error_msg}")

                except json.JSONDecodeError as e:
                    logger.error(f"ë‰´ìŠ¤ ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    logger.error(f"ìœ íš¨í•˜ì§€ ì•Šì€ JSON ì½˜í…ì¸ : {msg.content[:200]}...")
                except Exception as e:
                    logger.error(
                        f"ë‰´ìŠ¤ ë¶„ì„ ë°ì´í„° íŒŒì‹± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True
                    )
            else:
                logger.debug(f"ë‹¤ìŒ ì´ë¦„ì˜ ToolMessage ê±´ë„ˆë›°ê¸°: {msg.name}")
        else:
            logger.debug(
                f"ì¸ë±ìŠ¤ {idx}ì˜ ë¹„-ToolMessage ê±´ë„ˆë›°ê¸°: {type(msg).__name__}"
            )

    logger.info(f"ToolMessage {tool_message_count}ê°œ ì²˜ë¦¬ ì™„ë£Œ")

    # ê¸°ë³¸ê°’ ì„¤ì •
    if not timeseries_prediction:
        logger.error("ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ì°¾ì§€ ëª»í•¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
        timeseries_prediction = TimeSeriesPrediction(
            prediction=0.0, confidence=0.0, timestamp=datetime.now().isoformat()
        )

    logger.info(
        f"ìµœì¢… ê²°ê³¼: ì‹œê³„ì—´ì˜ˆì¸¡={timeseries_prediction is not None}, ê°ì„±ë¶„ì„ê°œìˆ˜={len(sentiment_analysis)}"
    )
    logger.info("parse_agent_result ì™„ë£Œ")
    logger.info("=" * 80)

    return timeseries_prediction, sentiment_analysis


def orchestrate_analysis(
    target_date: Optional[str] = None,
    commodity: str = "corn",
    context: str = "ê¸ˆìœµ ì‹œì¥ ë¶„ì„",
    return_agent_result: bool = False,
    **kwargs,
) -> Union[OrchestratorOutput, Tuple[OrchestratorOutput, dict]]:
    """
    Orchestrator ë¶„ì„ ë¡œì§
    """
    logger.info("=" * 80)
    logger.info("orchestrate_analysis ì‹œì‘")
    logger.info(
        f"íŒŒë¼ë¯¸í„°: target_date={target_date}, commodity={commodity}, context='{context}'"
    )
    logger.info(f"ì˜µì…˜: return_agent_result={return_agent_result}")
    if kwargs:
        logger.debug(f"ì¶”ê°€ kwargs: {kwargs}")

    try:
        summarizer = get_llm_summarizer()

        # ë¶„ì„ ê¸°ì¤€ì¼ì´ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
        if not target_date:
            target_date = datetime.now().strftime("%Y-%m-%d")
            logger.info(f"target_date ë¯¸ì œê³µ, ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©: {target_date}")
        else:
            logger.info(f"ì œê³µëœ target_date ì‚¬ìš©: {target_date}")

        logger.info(
            f"summarizer.summarize í˜¸ì¶œ: context='{context}', target_date={target_date}, commodity={commodity}"
        )
        result = summarizer.summarize(
            context=context, target_date=target_date, commodity=commodity
        )

        logger.info("Summarizer ì‹¤í–‰ ì™„ë£Œ")
        logger.debug(
            f"ê²°ê³¼ í‚¤: {list(result.keys()) if isinstance(result, dict) else 'ë”•ì…”ë„ˆë¦¬ ì•„ë‹˜'}"
        )

        agent_result = result.get("agent_result", {})
        logger.info(
            f"agent_result ì¶”ì¶œ: íƒ€ì…={type(agent_result)}, messages_ì¡´ì¬={'messages' in agent_result if isinstance(agent_result, dict) else 'N/A'}"
        )

        logger.info("agent result íŒŒì‹± ì¤‘...")
        timeseries_prediction, sentiment_analysis = parse_agent_result(agent_result)

        logger.info("OrchestratorOutput ìƒì„± ì¤‘...")
        llm_summary = result.get("summary", "")
        logger.debug(f"LLM ìš”ì•½ ê¸¸ì´: {len(llm_summary)} ë¬¸ì")
        logger.debug(
            f"LLM ìš”ì•½ ë¯¸ë¦¬ë³´ê¸°: {llm_summary[:200]}..." if llm_summary else "ë¹ˆ ìš”ì•½"
        )

        output = OrchestratorOutput(
            timeseries_prediction=timeseries_prediction,
            sentiment_analysis=sentiment_analysis,
            llm_summary=llm_summary,
        )

        logger.info("OrchestratorOutput ìƒì„± ì™„ë£Œ")
        logger.info(
            f"ì¶œë ¥ ìš”ì•½: ì‹œê³„ì—´ì˜ˆì¸¡ê°’={output.timeseries_prediction.prediction:.2f}, ê°ì„±ë¶„ì„ê°œìˆ˜={len(output.sentiment_analysis)}, ìš”ì•½ê¸¸ì´={len(output.llm_summary)}"
        )

        if return_agent_result:
            logger.info("agent_resultì™€ í•¨ê»˜ output ë°˜í™˜")
            logger.info("orchestrate_analysis ì™„ë£Œ")
            logger.info("=" * 80)
            return output, agent_result
        else:
            logger.info("outputë§Œ ë°˜í™˜")
            logger.info("orchestrate_analysis ì™„ë£Œ")
            logger.info("=" * 80)
            return output

    except Exception as e:
        logger.error("=" * 80)
        logger.error(f"orchestrate_analysisì—ì„œ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        logger.error(
            f"ì‹¤íŒ¨ ì‹œì ì˜ íŒŒë¼ë¯¸í„°: target_date={target_date}, commodity={commodity}, context='{context}'"
        )
        logger.error("=" * 80)
        raise
